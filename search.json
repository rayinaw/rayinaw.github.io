[{"title":"Học cách viết và hiểu một Kubernetes YAML files","date":"2023-12-10T14:41:44.000Z","url":"/2023/12/10/writing-a-kubenetes-yaml/","categories":[["undefined",""]],"content":"Học cách viết và hiểu một Kubernetes YAML filesTổng quanỞ bài viết trước mình đã nói sơ qua về kubenetes, trong bài viết này chúng ta sẽ tập trung vào cách viết và tạo một kubenetes pod, service,… Ở đây mình sử dụng minikube để demo, các bạn có thể cài đặt theo hướng dẫn ở đây. PodPod là đơn vị nhỏ nhất trong kubenetes, bên trong nó sẽ chứa những container. Các container bên trong sẽ dùng chung một địa chỉ ip của pod và không gian port. Địa chỉ ip của pod chỉ là một địa chỉ ip nội bộ, không phải ip của cluster. Thông thường, người ta sẽ chỉ chạy duy nhất một container bên trong một Pod, và chỉ có một vài trường hợp số ít, khi cần một số helper như ghi log hay một helper gì đó người ta mới chạy nhiều container bên trong một Pod. Về miệc chạy multi container có thể xem thêm ở đây. Demo Pod test-pod.yaml Một file yaml với kind Pod sẽ có dạng như trên, ngoài ra ta có thể quản lý các pod bằng cách thêm các labels cho Pod: Chạy lệnh kubectl apply -f test-pod.yaml: Ta đã tạo thành công một Pod, tuy nhiên ta không thể truy cập vào nginx mặc dù đã có thuộc tính containerPort: 80: Tại sao lại vậy? Lý do là vì Pod chỉ là một đơn vị trong một cluster, do đó nó chỉ có thể truy cập bên trong cluster đó. Để đưa port đó ra ngoài, ta cần sử dụng đến Service. Service Service được dùng để public port của Pod ra ngoài, để xác định Pod nào cần public port ta cần chỉ định Selector trỏ đến label của Pod đó. Một file yml của Service sẽ có dạng như trên. name: tcp: chỉ định giao thức trên port. Có 4 loại type của Service: type: ClusterIP: Nếu ta chỉ định là ClusterIP thì service của chúng ta chỉ có thể truy cập bên trong cluster và không thể truy cập từ bên ngoài ví dụ như truy cập từ browser. Ta sử dụng ClusterIP nếu service đó chỉ là một internal service. Ví dụ như một microservices, ta chỉ muốn nó chạy nội bộ và chỉ có microservices khác giao tiếp với nó. Ta thấy nó được cấp một địa chỉ ip, bây giờ các service khác ở trong cùng cluster có thể tương tác với nó bằng ip trên hoặc  type: NodePort NodePort cho phép chúng ta expose port để có thể truy cập bên ngoài cụm, port expose ra sẽ được truy cập từ bằng nodePort. Ta chỉ có thể chỉ định NodePort nằm tròng khoảng 30000-32768. ReplicaSetsReplicaSet được dùng để duy trì tính ổn định của Pod khi tạo ra nhiều bản sao của Pod đó. Nếu một Pod trong số Replicas đó crash thì server vẫn có thể duy trì nhờ vào các bản sao. Viết một file Replicas type khá đơn giản, ta chỉ cần wrap Pod vào trong spec như sau: Pod được quản lý bởi ReplicaSet nên ta có thể bỏ name của Pod trong phần metadata của Pod. Tương tự như service, ta cầng dùng đến selector để chỉ định Pod nào cần Replica. Apply file trên: Pod đã được cấp tên ở trong replicaset nên đó là lý do ta không cần metadata name. DeploymentDeployment là một khái niệm nâng cấp hơn của ReplicaSet, nó tương tự như ReplicaSet nhưng điểm khác biệt là giúp ứng dụng “rolling updates”. Rolling updates cho phép cập nhật của Deployments diễn ra mà không gây gián đoạn bằng cách cập nhật từng đợt Pod một cách tăng dần với các phiên bản mới. Cách deployment rolling updates: Giả sử ban đầu ta có một tập ReplicaSet từ deployment như sau: Bây giờ ta muốn update Pod từ v1 thành v2, ta sửa file yaml và appy nó trên kube. Sau khi apply, kube sẽ tiến hành tạo một ReplicaSet mới với Pod v2: Sau khi ReplicaSet mới được hoàn thiện, và sẵn sàng cho request. Kube sẽ tiến hành xóa các Pod trong ReplicaSet cũ, tuy nhiên ReplicaSet vẫn ở đấy với 0 Pod: Demo xyz-deployment.yml Bây giờ đổi version của nginx để xem cách deployment rolling update: Ngoài ra ta có thể xem quá trình rollout đơn giản hơn bằng lệnh rollout: "},{"title":"Gobuffalo Soda-cli","date":"2023-07-17T08:45:07.000Z","url":"/2023/07/17/gobuffalo-soda-cli/","categories":[["undefined",""]],"content":"Install Tạo database Cách 1: Sử dụng file database.yml: Sau khi tạo file database.yml, ta chạy lệnh soda create -a để tạo database. Cách 2: Sử dụng cli để tạo trực tiếp: soda create -e test Database MigrationsTạo một thư mục migrations để quản lý các file .fizz và .sql Gobuffalo có sử dụng một gói quản lý fizz để dễ dàng hơn trong việc viết các câu lệnh tạo bảng,… Tuy nhiên ta cũng có thể sử dụng sql migration. Fizz migrationTạo một migrations: Ví dụ: Hai file 20230717051256_create_users_table.down.fizz, 20230717051256_create_users_table.up.fizz được tạo ra. Sql migration Viết một fizz fileVí dụ ta tạo một bảng users: .up.fizz file: .down.fizz file: Sau khi set xong, ta chạy lệnh soda migrate up hoặc soda migrate để tạo table. Sau khi chạy thành công ta có thể thấy cấu hình được dump ra từ sql file. "},{"title":"Kubernetes learning","date":"2023-06-23T14:53:41.000Z","url":"/2023/06/23/kubernetes-learning/","tags":[["Docker","/tags/Docker/"],["DevOps","/tags/DevOps/"]],"categories":[["DevOps","/categories/DevOps/"],["Docker","/categories/DevOps/Docker/"]],"content":"Kubernetes learningDocker vs KubernetesDocker và containerTrước khi đi vào kubernetes thì ta sẽ đi qua docker và container trước. Trong mô hình Virtual Machine, mỗi VM đều có hệ điều hành riêng (guest OS) và một bản sao của kernel của hệ điều hành đó. Khi bạn khởi động một VM, nó sẽ khởi động guest OS, và sau đó các ứng dụng và dịch vụ chạy trên guest OS này. Mỗi VM hoạt động như một máy tính ảo hoàn chỉnh với hệ điều hành độc lập. Khác với VM, Containers là một công nghệ ảo hóa mức ứng dụng, nó không cần Guest OS mà trực tiếp chia sẻ với nhau Host OS thông qua Docker Engine. KubernetesCũng là ứng dụng quản lý container, nhưng khác với Docker là công cụ tạo và quản lý container độc lập, Kubernetes là hệ thống orkestrasi container mạnh mẽ giúp quản lý, mở rộng, và tự động hóa quá trình triển khai và quản lý ứng dụng container phức tạp. Kubernetes Architecture Cluster Cluster (cụm) là một nhóm các Node (là các máy ảo), trên Cluster sẽ có môi trường Kubernetes. Một cụm Kubernetes (Kubernetes cluster) bao gồm control plane nodes (hay còn gọi là Master nodes quản lý Cluster) và các worker nodes. Master chịu trách nhiệm quản lý cụm và master điều phối tất cả các hoạt động trong cụm. Mỗi worker node xem như một máy riêng và có một kubelet, là proxy quản lý node và giao tiếp với Kubernetes Master node. Control Plane (Master node)Control plane chịu trách nhiệm điều phối vùng chứa và duy trì trạng thái của Cluster. Control plane bao gồm những thành phần sau: kube-apiserver etcd kube-scheduler kube-controller-manager cloud-controller-manager Worker nodesCác worker nodes là nơi chạy các ứng dụng containerized. Gồm những thành phần sau: kubelet kube-proxy Container runtime Pods Trong Docker, các container là đơn vị nhỏ nhất để triển khai. Tuy nhiên, Kubernetes đưa ra một đơn vị mới là Pod làm đơn vị nhỏ nhất. Pod là một tập hợp các containers, chúng chia sẻ một không gian mạng và bộ nhớ. Điều này giúp dễ quản lý các containers hơn. Mỗi Pod sẽ có một địa chỉ ip riêng. Ví dụ một Pod sẽ bao gồm 2 containers: Một server nginx chạy trên port 80 Một server backend nodejs chạy trên port 3000 Pod sẽ được mô tả bằng một tệp YAML, và khi triển khai lên Kubernetes, nó sẽ tạo ra một Pod ví dụ như sau: Đặt tên file trên và chạy lệnh kubectl apply -f your-file.yaml là ta có thể triển khai một Pod trên kubernetes. Những thành phần và khái niệm cơ bảnBasic concepts ReplicaSet: Được định nghĩa khi khai báo kind của app, được sử dụng để quản lý và đảm bảo số lượng bản sao (replicas) của Pod. Giúp đảm bảo tính sẵn sàng nếu một trong những bản sao bị lỗi. Ví dụ ta có một server nginx. Để đảm bảo tính sẵn sàng và dự phòng cho trường hợp lỗi, ta khai báo ReplicaSet với số lượng replicas là 3 như sau: Deployment: Có nhắc đến ở dưới phần demo. Service: Định nghĩa cổng vào dịch vụ (service) và cung cấp một địa chỉ IP và cổng cho ứng dụng khác kết nối tới. Nó sử dụng Label Selector để xác định các Pod cụ thể mà nó liên kết và cung cấp một cách thống nhất để truy cập các ứng dụng trên cụm Kubernetes.Ví dụ ta có một ứng dụng web được triển khai trên Kubernetes bằng một số Pod, bây giờ ta muốn nó có thể được truy cập từ bên ngoài cụm Kubernetes, ta sẽ sử dụng service như sau: metadata: Xác định tên của Service (ở đây là “my-service”). selector: Sử dụng Label Selector để xác định những Pod nào sẽ thuộc về Service (ở đây là các Pod có label “app: my-app”). ports: Xác định cổng ngoài (port) và cổng mục tiêu (targetPort) mà Service sẽ sử dụng để chuyển hướng truy cập. Bây giờ, ta chỉ cần truy cập bằng ip của cluster  Kubernetes Control Plane ComponentsTạo một ứng dụng đơn giản với kuberctlTạo một AKS Cluster với Azure cloud serviceĐầu tiên vào  chọn loại Kubernetes service để tạo một AKS Cluster mới. Xem hướng dẫn thêm ở đây. Kết nối đến ClusterĐầu tiên ta cần config kubectl kết nối đến Kubernetes cluster: Sau khi chạy lệnh xong, ta sẽ nhận được kết quả: Merged &quot;AKSCluster&quot; as current context in /home/azureuser/.kube/config Chạy lệnh kubectl get nodes để xem trạng thái Cluster. Vậy là Azure đã bắt đầu tính phí rồi :D, sử dụng xong nhớ xóa cluster vừa tạo nhé. Kubernetes YAML FileMọi Configuration file trong Kubernetes gồm 3 phần: Header: gồm hai trường như sau: apiVersion: Xác định phiên bản API của Kubernetes, thường là v1. kind: Xác định loại đối tượng mà file YAML định nghĩa. metadata: chứa thông tin mô tả về dữ liệu, tài nguyên. Bao gồm các trường sau: name: Tên của app labels: specification: Demo cho Kind Deployment, Service, PodPodThường ta sử dụng kind: Pod với những ứng dụng đơn lẻ, tác vụ đơn giản như nginx, Redis, các container ghi log,… Ví dụ: Tạo file name &lt;name&gt;.yaml ví dụ pod.yaml Khởi chạy: Tương tác với container trong pod: kubectl exec -h để xem thêm những câu lệnh khác. Xóa pod: PS /home/azureuser/test&gt; kubectl delete pod my-app-pod Pod templateỞ trên là ta chỉ build riêng pod. Nhưng với một số Kind khác như Deployment, Job, DaemonSet thì để setting cho pod, ta phải định nghĩa thêm Pod template. Ví dụ: Xóa jobs: PS /home/azureuser/test&gt; kubectl delete job hello DeploymentDeployment là một tài nguyên trong Kubernetes để quản lý và duy trì một nhóm các Pod . Với kind: Pod thì ta chỉ có thể chạy riêng lẻ từng ứng dụng. Nhưng nếu ta muốn tạo nhiều bản sao của Pod và đảm bảo duy trì các Pod, kind: Deployment sẽ giúp ta điều đó. Số pod sẽ được định nghĩa ở trường replicas của Deployment. Khi tạo một Deployment, bạn chỉ cần xác định mẫu Pod (Pod template) và các nhãn (labels) để Deployment theo dõi. Deployment sẽ sử dụng mẫu Pod để tạo và duy trì các bản sao của Pod. Nếu một Pod không phản hồi, Deployment sẽ thay thế nó để đảm bảo số lượng Pod. Cũng như nếu vượt quá thì nó sẽ giảm số Pod. Lưu ý:Nếu container bị lỗi, Pod vẫn được coi là hoạt động bình thường và không có thay đổi trong Deployment. Một ví dụ đơn giản: my-app-deployment đã được đưa lên Deployment, và nó tạo ra 3 pods khác nhau. Tuy nhiên các pods vẫn chưa READY. Xem trạng thái của Deployment: kubectl rollout status deployment/my-app-deployment Bây giờ ta thử xóa một pod để xem Deployment làm gì: Như kết quả ở trên, Deployment đã phát hiện pod bị xóa và ngay lập tức tái tạo lại pod. Để xóa Deployment vừa tạo, ta dùng lệnh: Kiểm tra Pod đang sử dụng: Câu lệnh cơ bảnEnvironment variable: Tham khảo:   "},{"title":"Nginx Learning Journey","date":"2023-04-15T04:55:36.000Z","url":"/2023/04/15/nginx-learning/","tags":[["Docker","/tags/Docker/"],["DevOps","/tags/DevOps/"],["Nginx","/tags/Nginx/"]],"categories":[["DevOps","/categories/DevOps/"],["Nginx","/categories/DevOps/Nginx/"],["Docker","/categories/DevOps/Nginx/Docker/"]],"content":"Cấu hìnhYêu cầu: Sử dụng HDH linux, ở đây mình dùng Ubuntu. Cài đặt docker Cài đặt node.js và npm Docker &amp; nginx cơ bảnĐể thuận tiện, ở đây mình xây dựng nginx trên docker. Bạn nào chưa biết dùng docker thì có thể xem bài viết cũ của mình ở đây. Cấu trúc file: Nội dung file docker-compose.yml: Nginx là một máy chủ web được cấu hình bằng tập tin nginx.conf, file cấu hình nginx thường được đặt trong /etc/nginx/nginx.conf. Cho nên chúng ta cần copy file nginx.conf vào /etc/nginx/nginx.conf ở volumes trong docker-compose.yml file. Nội dung file nginx.conf: Khởi chạy: docker compose up -d hoặc nếu bạn đã cài gói docker-compose thì dùng docker-compose up -d. Dùng docker ps để xem container đang chạy. Nó đã chạy trên port 80, bây giờ truy cập localhost:80 để xem kết quả. Uke, server đã chạy nhưng chỉ đơn giản là trả về file có nội dung Hello World. Ta cùng học tiếp nhé~ Chạy docker compose down để gỡ container đi, nếu bạn có cài những container khác mà không muốn mất thì nhớ chỉ định đúng container để gỡ, ở đây là docker compose down reverse_proxy_demo Render html fileTạo thêm file html&#x2F;index.html: Cây thư mục: Đưa thư mục html vào container: Nắm một xíu về chỉ thị root trong nginx: Chỉ thị root được sử dụng để chỉ định đường dẫn tới thư mục gốc (root directory) chứa các tập tin tĩnh (ví dụ: các tập tin HTML, CSS, JavaScript, hình ảnh, v.v.) được phục vụ bởi Nginx. Nếu bạn đặt root /html; trong cấu hình Nginx, thì khi có yêu cầu truy cập đến server, Nginx sẽ tìm kiếm các tập tin tĩnh trong thư mục &#x2F;html để phục vụ cho yêu cầu đó. Chỉnh sửa file nginx.conf: Hoặc chúng ta có thể đặt đường dẫn root cho toàn bộ server: Khởi chạy docker compose up -d. Truy cập localhost, file index.html đã được khởi chạy trên browser. Đặt chỉ thị error_page để xử lý 404 not FoundThường thì này cũng không cần thiết lắm, nhưng mình có thể tự xử lý status 404 riêng. Thêm file 404.html vào thư mục html. Thêm chỉ thị error_page: Khởi chạy: docker compose up -d (nhớ docker compose down trước nhé). Truy cập localhost/abjdkje, trang lỗi đã được đổi thành trang 404.html của mình. Chỉ thị proxy_passCông dụng của nginx là điều hướng người dùng,… nên proxy_pass là một điều mà không thể không nhắc đến. Mình sẽ tạo một node.js web app cơ bản để demo cho rõ nhé. Thêm thư mục app: Đi đến thư mục app gõ npm init -y Tiếp theo chạy lệnh npm install express Tạo file app.js: Tạo file Dockerfile: Sau khi chạy xong ta sẽ có cây thư mục như sau: Chỉnh sửa docker-compose.yml: Notes: Trong một môi trường Docker Compose, các dịch vụ (services) được định nghĩa trong docker-compose.yml được xem như các tên miền. Khi bạn đặt tên cho dịch vụ trong docker-compose.yml (ví dụ: node-app), Docker Compose sẽ tạo một mạng mặc định giữa các dịch vụ và sử dụng tên của dịch vụ đó làm tên miền để chúng có thể giao tiếp với nhau. Để nginx chuyển hướng đến node-app thì chúng ta phải set tên miền là  tuy nhiên do ở đây mình đặt tên lại cho container là node_app_demo nên chúng ta sẽ set là . Nếu chúng ta đặt là  thì nginx sẽ chuyển hướng đến localhost của container nginx chứ không phải là node_app_demo. Cấu hình lại nginx.conf: Với cấu hình trên, khi người dùng truy cập đến  thì nginx sẽ điều hướng đến container node_app_demo. Khởi chạy: docker compose up -d Thư mục của mình để ở đây"},{"title":"Phân tích chuỗi Commons Collections 3","date":"2023-03-20T14:46:42.000Z","url":"/2023/03/20/CommonsCollections3/","tags":[["Java","/tags/Java/"],["Deserialization","/tags/Deserialization/"],["Commons Collections","/tags/Commons-Collections/"]],"categories":[["Java","/categories/Java/"],["Deserialization","/categories/Java/Deserialization/"]],"content":"Một vài kiến thức cần nắmBài viết này mình sử dụng template từ 3 bài viết trước về CC1-Lazymap, cc1-TransformedMap và CC2 nên để có thể hiểu được các bạn nên đọc 3 bài kia trước nhé. Môi trường JDK8u65 Commons-Collections 3.2.1Thêm Commons-Collections 3.2.1 vào project bằng dependencies (pom.xml file): Phân tíchSơ đồ tóm tắt chuỗi. CC2, CC3, CC4 đều được xây dựng dựa trên TemplateImpl. Mình đã xây dựng phần này ở bài viết về cc3, nên bài này mình sẽ sử dụng lại nó. Đoạn code trigger lớp TemplatesImpl: Ở CC2, chúng ta lợi dụng thực thi hàm newTransformer thông qua InvokerTransformer.newTransform(). Còn với CC3 là gì thì chúng ta cùng nhau đi tiếp nào. Tìm kiếm ta thấy có lớp TrAXFilter gọi đến nó ở trong hàm tạo. Đi đến hàm tạo của TrAXFilter phân tích một chút (phân tích trước chứ có cái có thể không xài nhé): _templates là một instance của interface Templates -&gt; _templates có thể là những lớp implements Templates (VD TemplatesImpl) _transformer là một instance của class TransformerImpl và ở đây nó có thực thi _transformer = (TransformerImpl) templates.newTransformer(); -&gt; Tìm class tạo ra TrAXFilter để nó thực thi hàm tạo. InstaniateTransformerTheo chain này, chúng ta sẽ dùng lớp InstantiateTransformer để tạo TrAXFilter ở hàm transform. Ở đây thì cũng khá dễ hiểu, trước tiên nó check Object mình truyền vào có phải là instance Class hay không, vậy thì chúng ta phải truyền Object loại khác với Class. Tiếp theo hàm này sử dụng reflection để tạo instance của một lớp nào đó. Mình sẽ phân tích rõ như sau: Constructor con = ((Class) input).getConstructor(iParamTypes); con là constructer của input truyền vào hàm transform. iParamTypes là mảng các kiểu dữ liệu truyền vào constructor của lớp TrAXFilter iArgs là mảng các tham số truyền vào constructor. Sau đó nó tạo instance của class cần tạo bằng con.newInstance(iArgs) Nhìn vào hàm tạo của InstantiateTransformer để xem các biến iParamTypes, iArgs được tạo như nào: Tóm gọn lại ý tưởng đến lúc này: * Ta có templates là instance của TemplateImpl cần thực thi newTransformer() * Tạo một instace của InstantiateTransformer với paramTypes là mảng chứa kiểu Class của tham số truyền vào constructor TrAXFilter (new Class[]{Templates.class}). args là mảng chứa tham số cần truyền vào constructor của TrAXFilter (new Object[]{templates}) * Thực thi instantiateTransformer.transform(TrAXFilter.class) Từ đây ta có một POC nhỏ như sau: ChainedTransformedTương tự như InvokerTransformer.transform, InstantiateTransformer implements Transformer nên thằng này có thể cho vào ChainedTransformed.Lợi ích của việc này như ở cc1-TransformedMap mình đã nói đó là chúng ta có thể trực tiếp thực thi mà không cần điều khiển đầu vào của hàm transform() bằng cách sử dụng ConstantTransformer Tương tự như cc1, các bạn có thể nhìn vào sơ đồ ở đầu bài viết, từ ChainedTransformed chúng ta có hai hướng đó là kết hợp với TransformedMap, hoặc Lazymap để tạo thành một chain. Hai cái này mình đã có bài viết về nó nên mình sẽ dùng lại luôn. Nếu muốn giải thích kĩ hơn thì các bạn xem lại ở bài viêt trước nhé~ ChainedTransformed + TransformedMapTiếp đến ta chỉ cần thêm đoạn này để trigger ChainedTransformer.transform. POC đến giai đoạn hiện tại: Hoàn thiện chain: Xây dựng xong chạy lên thì không thấy máy tính bật :) check đi check lại, tưởng là có vấn đề gì hóa ra jdk-1.8.0_342 mình đặt tên là 1.8.0_65 nên không chạy được :). Cái phần này mình chỉ lấy lại template từ bài viết trước, nếu các bạn chưa xem thì xem bài đó để hiểu nó là gì nhé~ ChainedTransformed + LazyMapChain hoàn chỉnh: Chạy file và máy tính đã bật lên! Phần thay đổi lấy từ cc1-lazymap, các bạn tìm lại đọc nhé~ Lời kếtChain này cũng không có gì quá khó khăn vì dựa trên phần đầu của cc1 và phần đuôi của cc2 mà mình đã phân tích. Chỉ khác là nó không đi qua InvokerTranformer mà đi qua InstantiateTransformer kết hợp với TrAXFilter.Qua ba bài viết về ba gadget chains mình đã dần thấy quen với việc đọc mã nguồn và sâu chuỗi các hàm, class. Mọi thứ dần trở nên dễ dàng hơn một xíu rồi. Hy vọng các bạn cũng như mình!Phần này mình sử dụng lại các đoạn code từ mấy chain trước nên nếu bạn chưa hiểu thì tìm đọc nhé. Chúc các bạn học tốt~ "},{"title":"Phân tích chuỗi Commons Collections 2","date":"2022-12-16T03:05:45.000Z","url":"/2022/12/16/CommonsCollections2/","tags":[["Java","/tags/Java/"],["Deserialization","/tags/Deserialization/"],["Commons Collections","/tags/Commons-Collections/"]],"categories":[["Java","/categories/Java/"],["Deserialization","/categories/Java/Deserialization/"]],"content":"Một vài kiến thức cần nắmTrước khi vào bài viết chúng ta cần nắm một số kiến thức sau: javassist Hiểu được ChainedTransformer ở CC1, nếu các bạn chưa biết thì tìm đọc lại bài CC1-TransformedMap của mình nhé. Môi trường JDK8u65 Commons-Collections 4.0Thêm Commons-Collections 4.0 vào project bằng dependencies: Phân tíchSơ đồ tóm tắt chuỗi. Từ TemplateImpl đến OS Command newTransformer()Trong lớp TemplateImpl tìm đến phương thức TemplateImpl.newTransformer(). Trong phương thức này nó gọi đến TemplateImpl.getTranslateInstance(). Đi đến phương thức này. Trong phương thức này, chúng ta cần quan tâm đến phương thức TemplateImpl.defineTransletClasses(). Nếu _name không null và _class null thì nó sẽ gọi đến TemplateImpl.defineTransletClasses(). Hai biến này hiện tại mình vẫn chưa rõ là gì bởi chưa rõ lớp TemplateImpl, cứ tiếp tục thôi. defineTransletClasses()Đi đến phương thức TemplateImpl.defineTransletClasses(). Đầu tiên để đi tiếp, chúng ta cần _bytecodes khác null. Trong phương thức này nó thực hiện tạo một TransletClassLoader, TransletClassLoader là một lớp con static của lớp TemplateImpl, và nó implement lớp Classloader. loader này thực hiện _class[i] = loader.defineClass(_bytecodes[i]), hàm này sẽ thực hiện phương thức defineClass của lớp ClassLoader ClassLoader.defineClass(null, b, 0, b.length) Mã nguồn của nó hơi khó hiểu nên mình đọc doc để biết nhanh chức năng của phương thức defineClass. Phương thức này thực hiện chuyển đổi một mảng byte thành một instance của class Class hay nói rõ hơn thì nó tạo ra một object của lớp Class, các bạn có thể đọc ở đây. Lớp được tạo ra từ _bytecodes[i] gọi đến getSuperClass trả về một super class và lưu vào biến superClass, tên của superClass sẽ được so sánh với “com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet”. Nếu như lớp cha của _class[i] là AbstractTranslet (Hay _Class[i] là class extends AbstractTranslet) thì _transletIndex sẽ được gán bằng i. Nói chung, sau phương thức defineTransletClasses(), ta có được vị trị của class extends AbstractTranslet là _transletIndex. _class[_transletIndex] sẽ là lớp chuyển từ _bytecodes và extends AbstractTranslet. getTransletInstance()Tiếp tục follow theo chain, đi đến phương thức getTransletInstance. Nó thực hiện _class[_transletIndex].newInstance(). Điểm hay là ở chổ này, khi một class được khởi tạo (Class.newInstance()) thì nó sẽ tự động thực thi constructor hoặc hàm static. Cái này thuộc về kiến thức OOP, mình sẽ nói kĩ hơn như sau: Khi tạo một instance của Class bằng phương thức newInstance, nó sẽ bao gồm hai bước: Load class: Khi một class được load lên bộ nhớ, các block static sẽ được thực thi. Các bạn chỉ cần hiểu vậy là đủ, còn nếu muốn hiểu sâu hơn thì tìm hiểu về ClassLoader (tốn thời gian lắm nhé!). Tạo object: Sau khi class được load lên, constructor sẽ được thực thi để khởi tạo một đối tượng. Ví dụ: Như đã phân tích ở trước _class[_transletIndex] là lớp chuyển từ _bytecodes, vậy nếu bytecodes chúng ta truyền vào này là của một class chứa static hay constructor chứa shell thì chúng ta sẽ trigger được nó.Có hai cách để làm điều này: 1. javassist Phương thức makeClassInitializer sẽ tạo một constructor. makeClassInitializer().setBody sẽ set nội dung cho hàm constructor này.Test thử với POC nhỏ sau: calc.exe vẫn chưa được kích hoạt, ở đây là do _tfactory chưa được set. _tfactory ở đây là một TransformerFactoryImpl nên chúng ta chỉ cần đặt là new TransformerFactoryImpl(). Máy tính đã được bật. 2. Tạo class rồi load trực tiếpKhởi tạo class, ở đây mình lấy static để làm ví dụ (cái nào cũng được).Đặt file Calc.java cùng thư mục với cc2. Ok, hướng đi là như thế, bây giờ chúng ta sẽ lợi dụng điều này vào class TemplatesImpl. _name không null _class null _bytecodes là bytecodes của lớp cần truyền vào. Kết hợp với lớp InvokerTransformerỞ cc1 theo TransformedMap, mình đã phân tích về lớp này. Mình sẽ tóm gọn lại như sau: Phương thức transform của lớp này sẽ thực thi phương thức mà ta truyền vào ở invokerTransformer của object truyền vào hàm transform. Ctrl + chuột trái nhấn vào phương thức transform của lớp InvokerTransformer để tìm lớp sử dụng phương thức này, lớp TransformingComparator là lớp chúng ta cần chú ý đến. Lớp này có phương thức compare sử dụng transformer.transform(). Phân tích một chút, hàm tạo của lớp này lấy một Transformer gán vào biến transformer, ở đây chúng ta có thể thay bằng InvokerTransformer. Hàm compare sẽ thực thi transform cho object truyền vào nó với Transformer được truyền từ hàm tạo. Từ đây chúng ta có đoạn code ngắn sau: Tiếp theo chúng ta cần lớp gọi đến TransformingComparator.compare. Đi đến phương thức siftDownUsingComparator của lớp PriorityQueue. Phương thức này sử dụng comparator.compare với comparator là một instance của interface Comparator, do đó nó có thể làm biến chứa cho các lớp implements interface Comparator, từ đây chúng ta có thể thay biến comparator bằng một TransformingComparator. Vì siftDownUsingComparator là một phương thức private nên chúng ta cần tìm phương thức gọi đến nó. Mò từ từ ta thấy được: readObject--&gt;heapify--&gt;siftDown--&gt;sifDownUsingComparator Hàm heapify loop hết các phần tử trong queue để siftDown(i, (E) queue[i]), ctr + chuột trái tiếp vào hàm heapify. Mảng queue được set ở hàm readObject rồi thực hiện heapify(). queue ở đây chỉ là đọc từ đối tượng mình serialize. Sau khi đọc dữ liệu gán vào queue, nó thực hiện heapify.Quá thuận lợi, bây giờ chỉ còn bước còn lại để xây dựng POC. Ta có hai phương án để thực hiện: Sử dụng ChainedTransformer để tự động thực hiện mà không cần thông qua queue Set giá trị cho queue Hoàn thiện chainSet giá trị cho queueĐể set giá trị cho queue, chúng ta sẽ sử dụng hàm PriorityQueue.add().Xem rõ phương thức này: Tuy nhiên như này thì nó đã chạy câu lệnh trước khi chúng ta thực hiện unserialize. Set breakpoint ở hàm add để xem lý do. Ta thấy ở lần add thứ 2, phương thức add gọi đến offer –&gt; siftUp –&gt; siftUpUsingComparator –&gt; Comparator.compare. Để không thực hiện cái này, ở hàm siftUp nó check Comparator nếu Comparator bằng null thì nó sẽ không thực hiện Comparator.compare. Do đó chúng có thể thực hiện set Comparator sau add giá trị vào priorityQueue. Tuy nhiên nếu không set comparator khi gọi đến siftUpComparable nó sẽ xuất hiện lỗi com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl cannot be cast to java.lang.Comparable. Do đó chúng ta phải nghĩ cách khác. Add trước rồi set sau, ta có full change: Sử dụng ChainedTransformerVề ChainedTransformer mình đã giải thích ở CC1-TransformedMap, các bạn có thể xem lại ở bài viết đó. Tuy nhiên, chúng ta gặp một vấn đề là máy tính được bật lên trước khi serialize object, dẫn đến việc dừng chương trình như đoạn mã dưới đây. Để giải quyết vấn đề này, chúng ta sẽ set giá trị vào sau khi Queue đã add xong: Máy tính đã được bật lên. Lời kếtMình đã hoàn thành cc2 theo hai hướng là ChainedTransformer và hướng set giá trị cho queue. Nếu thuần cc2 thì sẽ theo hướng queue, kiến thước khác với cc1 nên các bạn có thể sẽ thấy ngợp lúc đầu, mình cũng đã giải thích kĩ ở phần đó, hi vọng sẽ giúp các bạn học nhanh hơn và không cảm thấy khó khăn.Lúc đầu phân tích mình cũng thấy khó hiểu và betak, nhưng sau mình cố gắng ngồi lại để phân tích thì dần dần cũng thấy ổn hơn, mong các bạn không như mình :). Chúc các bạn học tốt~ "},{"title":"Phân tích chuỗi Commons Collections 1 với LazyMap","date":"2022-12-14T20:48:35.000Z","url":"/2022/12/15/CommonsCollections1-LazyMap/","tags":[["Java","/tags/Java/"],["Deserialization","/tags/Deserialization/"],["Commons Collections","/tags/Commons-Collections/"]],"categories":[["Java","/categories/Java/"],["Deserialization","/categories/Java/Deserialization/"]],"content":"Trong bài viết trước mình đã phân tích lỗ hổng deserialization của TransformMap trong chuỗi CC1, và trong bài viết này mình sẽ thực hiện deserialization theo hướng của lớp LazyMap. Phân tích InvokeTransformerPhần đuôi của chuỗi này cũng tương tự như chuỗi trước là InvokerTransformer, mình sẽ không phân tích lại lớp này. Như bài viết trước đã nói chúng ta cần tìm lớp gọi đến phương thức transform của lớp InvokerTransformer. Ctrl + Chuột trái click vào phương thức transform Phương thức này được sử dụng ở LazyMap.get() Xem factory là gì nào~ Lớp này sử dụng Overloading cho hàm tạo và hàm decorate, và ở đây có kiểu truyền vào cho factory là Transformer hoặc Factory, do đó chúng ta có thể truyền vào factory một Transformer rồi cho factory.transform(Runtime.getRuntime) như chain trước. Ở bài viết trước, có một vấn đề gặp phải là lớp Runtime không implements serialize và không thể điều khiển được tham số ở trong hàm setValue. Và chúng ta đã thấy được cái tiện lợi của lớp ChainedTransformer và ConstantTransformer. Nên mình sẽ sử dụng lại đoạn này để bỏ đi một vài bước không cần thiết. Đã mở được máy tính. Tuy nhiên như thế vẫn chưa đủ, chúng ta cần tìm lớp nào gọi đến phương thức LazyMap.get(). Và với chuỗi này, chúng ta sẽ tập trung đến lớp AnnotationInvocationHandler. AnnotationInvocationHandler.invoke() Trong hàm invoke của AnnotationInvocationHandler có dòng thực hiện phương thức get Object var6 = this.memberValues.get(var4);: this.memberValues ở đây là một map, chúng ta có thể cast nó sang LazyMap để lợi dụng LazyMap.get(). Như bài viết trước đã nói, lớp này là lớp kiểu default và constructor cũng là default nên chúng ta phải khởi tạo nó bằng Reflection. Đoạn code khởi tạo một AnnotationInvocationHandler, chỉ dừng ở việc khởi tạo và mình chưa làm những bước tiếp theo. Lớp này đã implements Serializable và có phương thức readObject(). Nên điều mà chúng ta cần tiếp theo là làm sao để lớp này thực hiện hàm invoke() trong phương thức readObject(). Và để thực hiện điều này chúng ta có thể sử dụng Proxy động. Dynamic ProxyCác phương thức gốc của lớp gốc đã được ghi đè bằng proxy, khi chúng ta thực hiện một phương thức của lớp đó thông qua proxy, proxy sẽ gọi đến hàm invoke rồi invoke phương thức của lớp này. Để hiểu thêm thì các bạn hãy đọc thêm về Dynamic Proxy trong Java. Bây giờ khi chúng ta gọi bất kì phương thức nào của proxyMap tương ứng với phương thức của lazyMap, nó sẽ gọi đến phương thức invoke và thực thi lazyMap.get() như mình đã phân tích ở trên. Chuỗi hoàn chỉnhĐể ý một chút ở hàm readObject của lớp AnnotationInvocationHandler this.memberValues là LazyMap chúng ta có thể truyền vào, và nó gọi đến entrySet(). Do đó khi readObject của lớp AnnotationInvocationHandler thực thi chúng ta có thể kích hoạt câu lệnh calc. Máy tính đã bật lên và chuỗi của chúng ta đã được xây dựng thành công~ Lời kếtProxy động là một kiến thức khá phức tạp với những bạn mới bắt đầu, mình khuyên các bạn chỉ cần học và hiểu cách sử dụng, đừng đào sâu vào code gốc bởi vì đó là một lượng kiến thức lớn do những người đi trước đã viết ra.Khi khởi tạo Proxy động cần đến class loader các bạn chỉ cần biết tải lớp nào cần class loader nào là đủ hoặc cứ cho đại null, không đúng thì abc.class.getClassLoader(), không cần tìm hiểu sâu vào nó. Chúc các bạn học tốt~ "},{"title":"Một bản ghi chép nhỏ về Docker","date":"2022-12-02T18:13:09.000Z","url":"/2022/12/03/docker-learning/","tags":[["Docker","/tags/Docker/"]],"categories":[["DevOps","/categories/DevOps/"],["Docker","/categories/DevOps/Docker/"]],"content":"Docker Command LineThao tác với mỗi lần chạy: -i và -t flag:Flag -i dùng để mở một tương tác với container, giữ cho nó tiếp tục được mở để thực thi những tác vụ tiếp.Flag -t dùng để tạo một pseudo-TTY(TTY tương tự như shell command trong linux), có nghĩa là tạo một shell của image rồi gắn vào terminal của mình. Docker container và -d flag:Khi chạy một cách bình thường, nó sẽ thực thi lệnh trực tiếp trên terminal của chúng ta (run container in foreground). Nhưng nếu chúng ta muốn nó không chạy trên terminal mà chạy ở trong container (run container in background).Ví dụ khi chạy lệnh sleep 1000: Để xem container đang chạy gõ docker ps(chạy trong background hoặc trên terminal), với container đã dừng gõ docker ps -a.Để không lưu lại container khi kết thúc docker container chúng ta dùng tag –rm, khi đó nếu quy trình kết thúc, docker sẽ tự động xóa container mà không lưu vào docker ps -a. –name flag:Đặt tên cho container mỗi lần chạy. -p flag:-p host_port:container_port : map cổng của container sang cổng máy thật. Chúng ta có thể map nhiều cặp port một lần bằng cách viết liên tiếp những cặp đó -p 8888:8080 80:4444.Ví dụ với tomcat server, tomcat là một open source web server thực thi Java servlet. Tomcat image này chạy ở port 8080: Đợi một lát để nó pull tomcat:8.0 về.Sau khi tải xong truy cập  trên browser. Tomcat đã chạy trên port 8888.Mình sẽ giải thích một chút: Tomcat này là một container (xem như là một máy ảo cho dễ hình dung nhưng hầu như không phải nhé ^^), nó chạy trên port 8080 của máy chủ tomcat này. Sau khi map qua cổng của localhost, cổng 8888 bây giờ sẽ như là cổng 8080 của máy chủ tomcat vậy. Docker log:Khi chạy một server qua terminal, nhật kí sẽ được ghi lại trực tiếp ở trên terminal. Khi chạy server qua container background để xem nhật kí của server chúng ta sử dụng câu lệnh docker logs Docker pull:Câu lệnh này dùng để lấy image từ trên hub của docker về. Ví dụ: Docker commit:Lệnh docker commit dùng để lưu những thay đổi trong file system của một Docker container vào image mới.Syntax: docker commit container_id repository_name:tag Docker build commandCâu lệnh docker build dùng để build một image từ một Dockerfile và context (nơi chứa những thứ như file php, java,… cần dùng để build). Hai thứ này được chứa trong cùng một folder, chúng ta gắn URL hoặc path để chỉ cho docker biết nơi chứa 2 cái này.Systax: -t flag dùng để đặt tên cho image. Dấu . để nói cho docker biết là tìm Dockerfile ở thư mục hiện tại, đây là path dẫn đến Dockerfile. Docker inspect:Mô tả thông tin low level của một container hay image. Gỡ Image và Container:Gỡ container: Đầu tiên phải dừng container đang chạy: docker stop &lt;id container&gt; Gõ docker ps -a để xem container đã dừng. docker rm -f &lt;id container đã dừng&gt;, -f flag ở đây là cờ bắt buộc gỡ, nên xài để gỡ thuận tiện hơn. Gỡ image: docker rmi &lt;tên image&gt; Docker Container’s FilesystemDocker images và layers:Một Docker images được xây dựng từ những layer. Mỗi layer đại diện cho mỗi lệnh trong Dockerfile, hay khi chạy lệnh bằng cách build thông qua Docker Commint Command ở phần sau.Mỗi câu lệnh có thay đổi file của một container đều tạo ra một layer mới. Để dễ hình dung chúng ta cùng đi qua ví dụ sau(Lấy từ docs.docker.com): Khi chạy file trên, nó sẽ tạo ra một Docker image mới có cấu hình theo các câu lệnh được chạy ở file trên. Câu lệnh LABEL không liên quan đến file hệ thống. Câu lệnh COPY thêm file ở thư mục chứa Dockerfile vào thư mục &#x2F;app của container. Tuy nhiên nó chỉ COPY trong quá trình chạy, để viết thay đổi đó vào layer của một image mới chúng ta cần chạy lệnh RUN make /app, khi này một layer mới mới được tạo. RUN rm -r $HOME/.cache gỡ thư mục cache, câu lệnh RUN này sẽ tạo ra một layer mới. Câu lệnh CMD cuối cùng chỉ để chạy command python khi container đang chạy và không tạo layer mới. Để xem các layers của một image chúng ta dùng lệnh docker image history &lt;id&gt; Docker container và writable layer:Docker container được tạo từ những docker image chỉ đọc hay không thay đổi được. Một docker container được tạo từ một image sẽ có thêm một lớp ở trên, lớp này được gọi là writable layerhay container layer. Mọi thay đổi trong container này sẽ được lưu vào lớp này. Khi nghiên cứu tới đây, mình có một thắc mắc là như đã nói, khi tạo một container việc thay đổi trong container này chỉ thay đổi lớp writable, rồi một image là không thay đổi được vậy thì tại sao chúng ta có thể thay đổi file hệ thống khi chạy container?. Theo mình hiểu thì nó như này: Khi chúng ta tạo một container, nó như là một máy mới được tạo ra vậy, chúng ta có thể thay đổi các file, folder trong máy mới này. Nó sẽ không ảnh hưởng gì đến các image cả vì nó riêng biệt mà. Thế rồi writable đó để làm gì? Khi thay đổi một container chạy từ một image rồi lưu lại thành một image mới, người ta sẽ lưu lại quy trình theo từng bước khiến file hệ thống bị thay đổi để tạo quá trình build image mới này có trình tự, và chắc cũng dễ dàng hơn. Và khi này những bước thay đổi đó sẽ được lưu xuống lớp writable, nếu chúng ta commit thay đổi này, những cái thay đổi thực hiện ghi lại trong lớp writable này sẽ được lưu lại theo những layer mới xếp chồng lên những layer của image cũ. Cách build một Docker image:Có hai cách để build một docker image: Commit những cái đã build, thay đổi trong một Docker container vào một image mới. Viết một Dockerfile.Bây giờ chúng ta cùng đi cụ thể vào từng cách để build một docker image. Build Docker Images by using Docker Commit Command:Giả sử chúng ta chúng ta có một base image là một debian (hệ điều hành tương tự linux), khi run image này nó không có Git command. Bây giờ để thuận tiện hơn chúng ta tạo một image mới có cài sẵn Git dựa trên debian image kia để chúng ta không phải cài lại Git mỗi lần chạy. Khi đó chúng ta có ba bước để thực hiện như sau: Tạo một container từ base image Install Git pakage trong container. Commit thay đổi trong container đã làm. Build Docker Images by writing DockerFile:Dockerfile là gì?Dockerfile là một file văn bản chứa những lệnh user cung cấp để build các image một cách tự động từ Dockerfile. Tên của Dockerfile phải là Dockerfile với D viết hoa ở đầu.Mỗi lệnh trong Dockerfile sẽ tạo một image layer mới đối với image này. Các lệnh sẽ chỉ định điều cần làm khi building image.Khi building image, Docker sẽ thực hiện quy trình tương tự như việc chúng ta build bằng commit command. Docker sẽ build lần lượt từng layer, khi build xong ở trong lớp writable container, nó sẽ viết xuống image mới, sau đó remove container đó, rồi lần lượt theo trình tự đó cho đến khi build đủ các layer trong Dockerfile. Việc viết xuống image mình không biết nó lưu ở đâu, nếu muốn tìm hiểu các bạn có thể tìm hiểu thêm về Docker daemon. Viết một Dockerfile:Câu lệnh đầu tiên trong Dockerfile là câu lệnh FROM (viết hoa để phân biệt với from arguments), dùng để chỉ định base image. Câu lệnh RUN: Dùng để chỉ định câu lệnh thực thi khi chạy base image. Câu lệnh RUN sẽ thực thi câu lệnh trong writable layer của container, sau đó commit container xuống image mới. Image mới này sẽ được sử dụng cho bước tiếp theo trong Dockerfile. Vì vậy mỗi lần RUN lệnh, nó sẽ tạo ra một image layer mới.Ví dụ tương tự như cách build qua Docker commit: Bây giờ truy cập vào folder chứa Dockerfile rồi gõ lệnh docker build -t ubuntu:own . Viết gọn các câu lệnh trên: Câu lệnh CMD:Khác với RUN, câu lệnh CMD sẽ không thực thi trong quá trình build image, nó chỉ thực thi khi khởi chạy container của image đó. Cái này nhìn ví dụ là dễ hiểu nhất: Chạy docker build -t test . để build image. Bây giờ chạy docker run test nó sẽ thực thi lệnh bên trong container này. Nó tương ứng với lúc chúng ta chạy lệnh docker run test ls /. Nếu chúng ta chạy lệnh trực tiếp trên command line như docker run test echo &quot;hello world&quot; thì nó chỉ thực thi lệnh này và bỏ qua lệnh được viết ở CMD trong Dockerfile. Câu lệnh ENTRYPOINTNhư ví dụ ở câu lệnh CMD, nếu chúng ta thực hiện docker run test echo &quot;hello world&quot; thì nó sẽ bỏ qua câu lệnh ls /. Đó là điều mà ta không mong muốn nếu như build image mà lỡ có ai mới học chạy chương trình của ta không được :). Do đó lệnh ENTRYPOINT giúp ta tránh điều đó: Bây giờ nếu chạy docker run test echo &quot;hello world&quot; thì nó vẫn chỉ chạy câu lệnh của ENTRYPOINT mà không chạy câu lệnh đăng sau docker run bởi vì nó là điểm cuối rồi. Docker cache: Nếu chúng ta build Dockerfile trên từ lần thứ 2 trở đi nó sẽ build nhanh hơn lần đầu tiên, bởi vì nó sử dụng lại layer đã build. Cái này liên quan đến docker cache. Mỗi layer riêng lẻ build ở trong mỗi lần build image, nó đều được ghi lại ở docker cache để sử dụng lại (riêng lẻ luôn chứ không phải sử dụng theo từng image). Ví dụ:Build image 1: Build image 2: Để không cache lại, chúng ta có thể sử dụng cờ --no-cache=true, mà cờ này hơi phế nhỉ, xài làm gì :).docker build -t test . --no-cache=true Câu lệnh COPY:Dùng để copy file hay thư mục từ build context (nơi chứa Dockerfile và những file cần thiết) vào file hệ thống của container. Ví dụ:Nội dung Dockerfile: Cùng thư mục với Dockerfile, tạo một file abc.txt ghi nội dung gì đó để test~ File abc.txt đã được copy vào thư mục src của container. Câu lệnh ADD:Câu lệnh này gần như tương tự với câu lệnh COPY, điểm khác ở đây là ADD không chỉ copy từ context mà còn có thể download từ internet và copy vào container. ADD cũng có thể tự động giải nén file được tại về với một vài định dạng được hỗ trợ. Câu lệnh WORKDIR:Câu lệnh này dùng để tạo folder chỉ định và truy cập đến folder đó. WORKDIR /app Xây dựng Flask web đơn giản qua Dockerfile:Python image: Python image là một image được xây dựng dựa trên base image là Alpine Linux. Trong Alpine Linux này người ta sẽ cài python compiler vào. Cái này là trả lời thắc mắc cho việc tại sao python là compile mà lại có workdir các kiểu ~ Đầu tiên tạo thư mục app. Trong thư mục này sẽ chứa Dockerfile và một thư mục khác chứa file app.py, đặt là app luôn cho dễ nhé.File app.py: Nội dung Dockerfile: Build image: docker build -t flaskweb .Chạy web: docker run -d -p 5000:5000 flaskwebBây giờ trên browser gõ  để truy cập web vừa chạy. Docker Container Links:Container links cho phép các container tìm ra nhau và trao đổi thông tin một cách bảo mật với nhau.Khi set up một cái link, chúng ta tạo ra một ống dẫn giữa source container và recipient container. Recipient container có thể truy cập, lấy dữ liệu và thêm dữ liệu từ source container.Links được thành lập bằng cách sử dụng container name. Lợi ích của việc này là chúng ta có thể thấy một cách rõ ràng hơn, không cần phải thông qua localhost.Ví dụ xây dựng một web app từ flask và redis (api để lưu trữ dữ liệu): index.html app.py Dockerfile Pull và khởi chạy redis: docker run -d --name redis redis:3.2.0Build image: docker build -t dockerapp:v0.1 .Khởi chạy image và link với redis: docker run -d -p 5000:5000 --link redis dockerapp:v0.1 Docker composeCác thuộc tín trong docker compose: version: chỉ ra phiên bản docker-compose đã sử dụng. services: thiết lập các services(containers) muốn cài đặt và chạy. image: chỉ ra image được sử dụng trong lúc tạo ra container. build: định nghĩa một môi trường xây dựng (build context) cho Docker image và các tham số liên quan đến quá trình xây dựng. Các trường con: Nếu muốn chỉ rõ, ta có thể sử dụng đến trường con context dockerfile: Xác định đường dẫn đến Dockerfile trong build context ports: thiết lập ports chạy tại máy host và trong container. restart: tự động khởi chạy khi container bị tắt. environment: thiết lập biến môi trường ( thường sử dụng trong lúc config các thông số của db). depends_on: chỉ ra sự phụ thuộc. Tức là services nào phải được cài đặt và chạy trước thì service được config tại đó mới được chạy. volumes: dùng để mount hai thư mục trên host và container với nhau. Cũng như ví dụ ở trên, thay vì chúng ta pull, build image rồi khởi chạy rườm rà. Chúng ta có thể viết một docker compose rồi khởi chạy chỉ với một câu lệnh docker-compose up. Docker compose file cần tuân thủ nghiêm ngặt thụt lề, mỗi lần thụt là 2 khoảng trắng. File name: docker-compose.yml Dockerfile phải đặt chung với context của trường build (ở đây là .) Khởi chạy gõ docker-compose up hoặc thêm cờ -d docker-compose up -d để treo trong container. Docker compose sẽ không build lại image nếu image đó đã tồn tại, vì vậy khi ta thay đổi một vài lệnh trong Dockerfile docker-compose vẫn lấy image cũ để thao tác. Để build lại một image mới, chúng ta cần sử dụng lệnh docker-compose build."},{"title":"Portswigger HTTP Request smuggling","date":"2022-12-02T15:22:15.000Z","url":"/2022/12/02/HRS-PortSwigger/","tags":[["HRS","/tags/HRS/"],["Portswigger","/tags/Portswigger/"]],"categories":[["HTTP Request Smuggling","/categories/HTTP-Request-Smuggling/"],["Portswigger","/categories/HTTP-Request-Smuggling/Portswigger/"]],"content":"Portswigger: HTTP Request smuggling:HTTP request smuggling, basic CL.TE vulnerability Yêu cầu: Làm cho server trả về lỗi “Unrecognized method GPOST”.Gửi yêu cầu đầu tiên đến server: Sau đó gửi một yêu cầu bình thường và lỗi sẽ triggered. HTTP request smuggling, basic TE.CL vulnerabilityCũng là kích hoạt lỗi “Unrecognized method GPOST”. Back-end không hỗ trợ chunked encoding nên sẽ là dạng TE.CL Uncheck update Content-Length: Gửi yêu cầu sau đến server sau đó gửi một request tùy ý. Giải thích: Một yêu cầu POST sẽ hợp lệ nếu có trường Content-Type hoặc Content-Length hoặc Transfer-Encoding, ở đây mình thêm trường Content-Type: application/x-www-form-urlencoded để tránh đôi khi có lỗi nó không xét 2 cái kia, không thêm cũng được không quan trọng. Ở đây như đề bài nói máy chủ back-end không hỗ trợ Transfer-Encoding: chunked nên chúng ta có thể để máy chủ front-end phân tích Transfer-Encoding: chunked và để cho máy chủ back-end phân tích Content-Length. 5d hex &#x3D; 93 decimal &#x3D; dòng 1 + \\r\\n + d2 + \\r\\n +d3 +\\r\\n + d4 + \\r\\n + aaaa Kết thúc chuỗi là số 0 và xuống dòng để máy chủ front-end phân tích Transfer-Encoding: chunked hợp lệ. Sau khi máy chủ front-end phân tích, nó thõa mãn và gửi đến back-end. Máy chủ back-end chỉ phân tích trường Content-Length và ở đây chỉ bằng 4 và bằng 5d + \\r + \\n nên phần còn lại sẽ là một yêu cầu mới. Bây giờ nếu chúng ta gửi tiếp một yêu cầu nữa cùng chung một connection TCP nó sẽ trigger lỗi Unrecognized method GPOST. Và để được như vậy thì chúng ta cần set thêm trường Connection: Keep-Alive hoặc Connection: Pipelining tuy nhiên với HTTP&#x2F;1.1 thì Connection: Keep-Alive luôn được bật trừ khi máy chủ set là close nên chúng ta cũng không cần thiết thêm vào (thêm cho chắc :P). HTTP request smuggling, obfuscating the TE headerỞ đây ta sẽ gửi một cái TE hợp lệ và một cái TE không hợp lệ để obfuscate server. Gửi 2 lần yêu cầu sau để trigger lỗi. HTTP request smuggling, confirming a CL.TE vulnerability via differential responsesBài này front-end chỉ xử lý Content-Length –&gt; CL.TE (chưa chắc nma theo đề thì z).Yêu cầu là đính chính lại nó dính lỗi CL.TE bằng cách để yêu cầu thứ 2 là một yêu cầu trả về lỗi 404 not found. Ở phần thứ 2 của request, ta có 2 cách để tạo một request hợp lệ: Gửi một POST request, khi đó nếu có request khác gửi đến thì nó sẽ gắn vào phần body –&gt; không bị lỗi 400 Cách 2 là sử dụng X-Ignore: abc, khi này phần sau request sẽ được gắn vào trường X-Ignore header và không gây ra lỗi 400. Gửi request với payload trên, sau đó gửi một request bất kỳ để solve lab. HTTP request smuggling, confirming a TE.CL vulnerability via differential responses Back-end server doesn’t support chunked encoding Triggering 404 Not Found response Gửi 2 lần request sau: Exploiting HTTP request smuggling to bypass front-end security controls, CL.TE vulnerabilityGửi 2 lần request sau: Kết quả trả về là Admin interface only available to local users, vậy là chúng ta cần truy cập đến admin page với host là localhost. Vì hiện tại server sẽ mặc định set cho ta host là 0a33008a039b2e88c01e9186008400ec.web-security-academy.net Payload cuối cùng: Exploiting HTTP request smuggling to bypass front-end security controls, TE.CL vulnerability back-end server doesn’t support chunked encoding nên chúng ta có thể nghĩ đến TE.CL Gửi 2 lần request sau: Phản hồi thứ 2 trả về Admin interface only available to local users, để bypass ta có thể thử thêm trường Host: localhost Gửi 2 lần request sau để solve lab này. Exploiting HTTP request smuggling to reveal front-end request rewritingFront-end server doesn’t support chunked encoding –&gt; ý tưởng là CL.TE Bài này tác giả bảo là có trường set IP cho client tương tự như X-Forwarded-For nên mình đã nghĩ đến X-Real-IP tuy nhiên gửi mãi không thấy kết quả gì. Hóa ra ý tác giả muốn bảo ở đây là thằng X-*-IP phần trong dấu * có thể tùy ý nên chúng ta cần tìm phần này. Để tìm được điều này chúng ta cần lợi dụng trường search. Gửi 2 lần yêu cầu sau: Phần yêu cầu sau sẽ được gắn vào sau thằng test và mình có thể thấy được nhờ trường search. Kết quả trả về như sau: X-*-Ip mỗi người mỗi khác nên các bạn phải tự tìm lấy nhé. Sau khi biết được cái này rồi thì rất đơn giản, chúng ta chỉ cần set IP là 127.0.0.1 để truy cập vào admin panel. Exploiting HTTP request smuggling to capture other user’s requests Lab này là dạng CL.TE Tác giả có lập trình sẵn là khi chúng ta gửi một request thì máy chủ sẽ tự động gửi 1 resquest. Request này sẽ đóng vai trò như nạn nhân để chúng ta lấy cắp cookie và đăng nhập vào tài khoản này. Ở đây để lấy cắp cookie chúng ta sẽ ghi request của nạn nhân vào form comment. Request như sau: Kết quả ở comment của trang : Có được cookie rồi chúng ta sẽ sử dụng nó để đăng nhập: Exploiting HTTP request smuggling to deliver reflected XSSĐầu tiên zô trang &#x2F;post?postId&#x3D;7 để tìm cách trigger xss thông qua trường User-Agent. Payload xss: User-Agent: aaa&quot;&gt;&lt;script&gt;alert(1)&lt;/script&gt; Sau đó gửi request này để nạn nhân truy cập vào trang web sẽ bị trigger xss: CL.0 request smuggling H2.CLTest H2.CL, ta trigger được HRS với payload sau (Nhớ uncheck update content length): Khi request tới resource, ta thấy nó được chuyển hướng đến location như sau: Thử sử dụng Host header để thay đổi location: Trong mã html, ta thấy nó có những thẻ script nhập mã js từ bên ngoài, vậy nếu ta giả mạo yêu cầu đúng lúc browser nhập mã js về thì ta có thể để browser nhập mã js chứa payload xss. Gửi một vài lần để bot truy cập và thời điểm browser của bot import mã js thì nó nhập mã js của ta. HTTP&#x2F;2 request smuggling via CRLF injectionThêm header foo: bar rồi chèn thêm CRLF và TE, trong body thêm giá trị tùy ý ta trigger được 404 not found Ở trong trang search, ta thấy nó lưu lại lịch sử search của người dùng. Lợi dụng tính năng này để đánh cắp cookie của người dùng: Gửi và đợi tầm 10s để bot truy cập: HTTP&#x2F;2 request splitting via CRLF injectionGửi request này 2 lần, ta trigger được 404 not found: Chỉ với CRLF, ta có thể cắt request thành nhiều request khác nhau. Vậy bây giờ ta chỉ cần áp dụng kĩ thuật Response queue poisoning: Ta sẽ queue request smuggle (request 2), sau khi người dùng request 3, server sẽ thực hiện và trả về response của request 2 cho phía nạn nhân và queue lại request 3. Bây giờ ta chỉ cần gửi request 4 thì ta sẽ nhận được response từ request 3 của người dùng. Sau một hồi không queue được, mình thử fix lại payload để server tự thêm \\r\\n thì mình đã bắt được request của admin: Truy cập admin panel và delete user carlos: Response queue poisoning via H2.TE request smuggling Front-end server doesn’t support chunked encoding. The front-end server is configured to cache certain responses. Vậy ta sẽ sử dụng kĩ thuật CL-TE ở đây, kết hợp với cache poisoning. Trigger được 404 not found với payload sau: Bypass double Host header: Bây giờ ta cần tìm một sink để có thể chuyển hướng về trang chứa script xss, ở tính năng next post ta có thể redirect: Ở phía server, yêu cầu sẽ không bị phụ thuộc vào trường host, nên dù có hay không thì nó vẫn request đến đúng địa chỉ server. Exploiting HTTP request smuggling to perform web cache deception &#x3D;&gt; CL.TE Trang web có thực hiện caching các file thường đa số người dùng đều nhập giống nhau như blog.svg hay tracking.js: Vậy bây giờ ta smuggle các request nhập blog.svg hay tracking.js thì ta có thể truy xuất api key từ kết quả trả về được smuggle và lưu vào cache tương ứng với các file này. Như ở đây, mình thực hiện smuggling request đến my account. Bây giờ request trả về ở những file khi bot request là response 302, nên gửi kiểu gì nó cũng trả về: Vậy bây giờ chỉ cần cầu may cho bot request đúng lúc, ta có thể double cơ hội thành công bằng cách check cache của 2 file blog.svg và tracking.js Kết quả: Bypassing access controls via HTTP&#x2F;2 request tunnellingConnection timeout có nghĩa ta đã giả được host. Request được downgrade trông như sau: Client-side desyncRequest đến &#x2F; sẽ được redirect đến &#x2F;en: Gửi 2 request với chung connection ta được trả về 2 response: Nếu ta thực hiện gửi trong browser với request 2 là một request bất kỳ thì response 2 do request &#x2F;404 sẽ trả về ở request 2. Test trên browser: Browser chỉ trả về mỗi response cho mỗi request, do đó ta chưa thấy 404 ở đây. Tuy nhiên nếu ta gửi tiếp một yêu cầu nữa thì 404 trả về cho fetch thứ 2: Test với request comment: Bắt được thành công request thứ 3. Response queue poisoning via H2.TE request smugglingServer queue response nên ta có thể capture được response mà admin login trả về, từ đó lấy cookie của admin. "},{"title":"Khái niệm cơ bản về HTTP request smuggling với HTTP/1.1","date":"2022-11-30T03:36:10.000Z","url":"/2022/11/30/http-request-smuggling-HTTP-1.1/","tags":[["HRS","/tags/HRS/"]],"categories":[["undefined",""]],"content":"Lời nói đầu:Bài viết này là về khái niệm và cách HRS xảy ra đối với HTTP&#x2F;1.1, với HTTP&#x2F;2.0 và thực hành các bạn có thể xem ở bài viết sau. Một vài kiến thức cần nắm:Keep-Alive và Pipelining:Keep-Alive và Pipelining được giới thiệu trong RFC-2616:Keep-Alive cho phép một kết nối TCP giữa Client và Server được tiếp tục gửi và nhận HTTP requests và responses thay vì mở lại kết nối sau mỗi lần Client yêu cầu. Theo như mình thấy thì một số server sẽ set out timeout cho một kết nối keep-alive, sau khi user 1 yêu cầu đến server và server gửi response về, kết nối vẫn được mở và user khác có thể sử dụng kết nối này. Để bật mode Keep-Alive chúng ta cần thêm trường Connection: Keep-Alive vào request. Pipelining cho phép client gửi nhiều yêu cầu HTTP một lúc mà không cần đợi phản hồi của server thông qua một kết nối TCP được mở, server sẽ phản hồi theo thứ tự mà request được gửi đi. Để bật mode Pipeline chúng ta cần thêm trường Connection: Pipelining vào request. Content-Length và Transfer-Encoding:Content-Length:Đối với một yêu cầu POST, bắt buộc phải có 1 hoặc hơn trong 3 phương thức Content-Length, Transfer-Encoding, Content-Type và đương nhiên nó phải đúng định dạng. Content-Length đề cập đến kích thước phần body của một yêu cầu HTTP tính bằng byte. Nếu một tệp văn bản được nén, thì Content-Length của nó sẽ là kích thước được nén. Tiêu đề Content-Length chỉ có ở POST request vì nó có trường nội dung còn GET request thì không. Transfer-Encoding:Transfer-Encoding chỉ ra kiểu truyền tải nào được sử dụng để truyền tải nội dung(phần body). Transfer-Encoding có nhiều kiểu truyền tải, nhưng với lỗi HRS chúng ta chỉ cần chú ý đến phương thức Transfer-Encoding: chunked. Với Transfer-Encoding: chunked Dữ liệu body sẽ được truyền theo từng khối. Bắt đầu bởi một số hex biểu thị số byte của nội dung đầu tiên, tiếp theo sau là data. Tiếp đến là lần lượt những đoạn hex, data như vậy. Để kết thúc nội dung byte cuối cùng sẽ là 0 và theo sau là \\r\\n. Một \\r\\n được gọi là một CRLF, độ dài không bao gồm CRLF. Ví dụ: Ở phương thức Transfer-Encoding chúng ta cần nắm cách đếm byte: Nếu dữ liệu trên 1 dòng thì không cần đếm \\r\\n sau nó. Nếu dữ liệu nhiều dòng như dòng E\\r\\n (bytes to send) ở trên thì chúng ta cần đếm hết kể cả \\r \\n (lưu ý \\r hay \\n chỉ tính là 1 byte), ở dòng cuối cùng của khối data này có \\r\\n chúng ta sẽ không đếm nó vào. Sau đó chuyển độ dài thành số hex tương ứng. Tham khảo thêm về Content-Length và Transfer-Encoding ở RFC-7230. Reverse proxy:Reverse Proxy là một loại proxy server, nó đóng vai trò là một server trung gian. Nó tiếp nhận yêu cầu từ user, rồi chuyển tiếp đến các máy chủ khác xử lý yêu cầu đó rồi trả về cho người dùng. Người dùng ở đây chỉ giao tiếp với reverse proxy server mà không biết về sự tồn tại của máy chủ khác.Cấu trúc của một request từ user đến một máy chủ có tồn tại reverse proxy như sau: user — request —&gt; reverse proxy — request—&gt; back-end server user &lt;— response — reverse proxy &lt;— response — back-end server Khái niệm web cache:Web cache sinh ra để nâng cao trải nghiệm người dùng. Khi người dùng yêu cầu như những dữ liệu như HTML, CSS, Javascript, image,…, server có thể sẽ lưu vào web cache để không phải thực hiện lại những truy vấn để lấy những dữ liệu đó, giúp cho việc lấy dữ liệu nhanh hơn, đỡ tốn tài nguyên hơn cho người dùng. Có một số loại web cache như sau:Web cache ở phía browser: Sau khi người dùng thực hiện request lần đầu tiên đến server, nếu server hỗ trợ cache ở browser người dùng, dữ liệu sẽ được lưu vào cache ở browser của người dùng (nên xóa lịch sử web hay có mục cache). Khi người dùng request những lần tiếp theo tương tự như yêu cầu đầu tiên, browser chỉ cần lấy từ cache của browser để render ra cho người dùng. Web cache phía Proxy Server: Nó thường là CDN caching. Nó hoạt động tương tự như browser caching tuy nhiên nơi lưu trữ cache ở đây là CDN server trên toàn thế giới. Ở đây nhiều user có thể dùng chung cache từ server gửi đến máy chủ CDN. Cách hoạt động các bạn có thể tham khảo thêm ở đây. Web cache phía Reverse Proxy server: Cũng hoạt động tương tự như hai kiểu trên, tuy nhiên cache được lưu trữ ở phía Reverse Proxy. Video tham khảo thêm về web cache: Yêu cầu của lỗi HRS:Để một lỗi HRS xảy ra, trang web cần đáp ứng những yêu cầu sau: Trang web bao gồm hai máy chủ front-end (reverse proxy) và máy chủ back-end. Máy chủ phải hỗ trợ Keep-Alive hoặc Pipelining để yêu cầu có thể gắn với yêu cầu của nạn nhân (Nếu bạn không hiểu thì cứ bỏ qua, đọc phần sau sẽ hiểu) Máy chủ front-end và back-end phân tích các trường Transfer-Encoding, Content-Length không nghiêm ngặt khiến cho quá trình phân tích mắc sai lầm phát sinh lỗi. HTTP request smuggling ở HTTP&#x2F;1.1CL (Content-Length) không bằng 0 và giả mạo Body:Máy chủ proxy cho phép yêu cầu GET mang nội dung, nhưng máy chủ phía sau không cho phép mang nội dung trong GET request, khi này máy chủ phía sau sẽ trực tiếp bỏ trường Content-Length và không xử lý nó. Từ đây nó sẽ phát sinh ra lỗi HRS. Ví dụ một request như sau: Máy chủ Proxy nhận được yêu cầu, do máy chủ proxy cấu hình sai nên GET request được mang body giả mạo của mình. Sau đó nó sẽ chuyển đến máy chủ phía sau, tại đây nó không chấp nhận trường Content-Length nên nó loại bỏ tạo thành 2 request. Và nếu máy chủ có sử dụng pipelining, nó sẽ xem như là hai yêu cầu riêng biệt.Yêu cầu thứ nhất: Yêu cầu thứ hai: CL-CL:Kĩ thuật tấn công CL-CL là một yêu cầu HTTP chứa 2 trường Content-Length. Theo RFC-7230, nếu máy chủ nhận được hai yêu cầu Content-Length và giá trị của 2 yêu cầu đó khác nhau thì nó sẽ trả về lỗi 400. Tuy nhiên đôi lúc sẽ có những máy chủ không tuân thủ nghiêm ngặt thông số này và dẫn đến HRS. Giả sử một kịch bản tấn công sẽ là cả máy chủ proxy và máy chủ gốc đều không trả về lỗi 400, và máy chủ proxy sử dụng trường Content-Length đầu tiên và máy chủ gốc sử dụng trường Content-Length thứ hai. Ví dụ một request như sau: Phân tích: Máy chủ proxy nhận Content-Length: 8\\r\\n, dòng thứ 5 trống là một dòng thông thường của yêu cầu POST nên không tính vào phần nội dung, 12345 + \\r + \\n + a = 8 bytes thõa mãn với trường Content-Lengthnên nó chuyển tiếp yêu cầu đến máy chủ back-end. Máy chủ Back-End nhận trường Content-Length: 7\\r\\n, sau khi đọc 7 kí tự đầu tiên là hết dòng thứ 6, máy chủ Back-End cho rằng quá trình đọc đã hoàn thành sau đó gửi response về cho client. Lúc này trong bộ đệm còn một kí tự a, máy chủ back-end sẽ xem như đây là một phần của yêu cầu (request) tiếp theo. Bây giờ giả sử như có một người dùng khác gửi một yêu cầu đến máy chủ: Dựa trên việc sử dụng lại kết nối TCP giữa máy chủ proxy và máy chủ back-end, a sẽ được kết hợp với yêu cầu này để tạo thành một yêu cầu mới: Lúc này tại máy khách sẽ nhận được một lỗi aGET request method not found, cho chúng ta biết được rằng HRS đã xảy ra. CL-TETrong trường hợp này, máy chủ Front-End sử dụng Content-Length và máy chủ Back-End sử dụng Transfer-Encoding. Giả sử một yêu cầu như sau: Máy chủ Front-End nhận trường Content-Length: 6\\r\\n, dòng thứ 6 không tính vào Content-Length, dòng 7-9 có 0 + \\r\\n + \\r\\n + a = 6 bytes thõa mãn, nên yêu cầu được chuyển đến máy chủ back-end.Máy chủ Back-End nhận Transfer-Encoding: chunked\\r\\n, khi nhận được cờ 0\\r\\n và dòng sau là \\r\\n máy chủ sẽ xem như là phần body đã kết thúc và lúc này kí tự a vẫn còn nằm trong bộ đệm. Tương tự như CL-CL nếu bây giờ có một yêu cầu gửi đến: Nó sẽ gộp kí tự a với request này thành: Và client sẽ nhận lỗi Unrecognized method aPOST có nghĩa là HRS đã xảy ra. TE-CLMáy chủ Front-End sử dụng tiêu đề Transfer-Encoding, máy chủ Back-End sử dụng tiêu đề Content-Length.Xét request như sau: Máy chủ front-end nhận Transfer-Encoding: chunked\\r\\n, khi đọc đến 0\\r\\n và \\r\\nở cuối, không có vấn đề gì xảy ra nên máy chủ front-end request đến máy chủ back-end. Máy chủ back-end nhận trường Content-Length: 4\\r\\n, vì độ dày chỉ 4 bytes tương đương 12 + \\r + \\n là đến hết dòng thứ 6, máy chủ back-end sẽ xem là đã kết thúc request và phần còn lại từ dòng 7 trở đi không được xử lý và máy chủ back-end sẽ coi đây là phần bắt đầu của yêu cầu tiếp theo. Tại thời điểm này nếu có một yêu cầu khác nó sẽ báo lỗi Unrecognized method aPOST, có nghĩa là HRS đã thành công. TE-TECả máy chủ front-end và máy chủ back-end đều sử dụng Transfer-Encoding nhưng bằng một cách nào đó chúng ta có thể gây nhầm lẫn cho máy chủ để một trong hai máy chủ front-end và back-end không xử lý Transfer-Encoding như bình thường, khi đó chúng ta có thể khai thác lỗ hỏng CL-TE hoặc TE-CL tùy theo cách xử lý của reverse proxy và back-end. Một số cách để gây rối cho máy chủ như sau: Giả sử chúng ta có một request như sau: Máy chủ Proxy nhận Transfer-Encoding: chunked\\r\\n, thấy yêu cầu hợp lệ nó gửi đến máy chủ back-end.Máy chủ back-end: Lúc này do tồn tại hai trường Transfer-Encoding: chunked\\r\\n và Transfer-encoding: cow\\r\\n nên khiến máy chủ bị rối, nó không biết nhận cái nào nên có thể bây giờ nó sẽ nhận Content-length: 4\\r\\n. 5c\\r\\n = 4bytes nên phần sau được xem như là một yêu cầu khác, và do máy chủ tồn tại pipelining nên nó được coi như là một yêu cầu khác biệt. Lúc này một lỗi Unrecognized method aPOST sẽ được trả về. Web cache poisoning thông qua HRS:Tham khảo:    "},{"title":"Tính năng mới của Mysql 8","date":"2022-11-27T15:13:20.000Z","url":"/2022/11/27/sqli-mysql8/","tags":[["Mysql","/tags/Mysql/"],["SQLi","/tags/SQLi/"]],"categories":[["Mysql","/categories/Mysql/"],["SQLi","/categories/Mysql/SQLi/"]],"content":"Tính năng mới của mysql8Câu lệnh TABLE Chức năng: Trả về các hàng và cột của bảng được chỉ định Trông thì tương tự như câu lệnh select. Kể cả kết hợp order. Tuy nhiên điểm khác ở đây là câu lệnh table sẽ lấy ra toàn bộ bảng, vậy nên where clause sẽ không có tác dụng, nó sẽ đưa ra lỗi. Câu lệnh VALUES Câu lệnh nhìn khá phức tạp, đơn giản nó chỉ đưa ra các row mà chúng ta định nghĩa. Ví dụ cho dễ hiểu: Câu lệnh này có thể kết hợp với union như sau: Sử dụng câu lệnh table để dump database: Để dump ra tên SCHEMA_NAME bằng hàm table ta sẽ sử dụng Boolean-based SQL Injection. Để dễ hình dung chúng ta cùng đi vào ví dụ: Lưu ý là nếu chúng ta cần tìm cột sau thì phải biết giá trị cột trước mới so sánh được, các cột sau không quan trọng. Ở đây giá trị của cột đầu tiên sẽ là def, cột thứ 2 là tên database, các cột sau là không quan trọng đối với chúng ta. Chúng ta cùng đi vào phần boolean của payload: Câu lệnh này ở đây phần sẽ tương đương với việc so sánh chuỗi thứ 2 thuộc (‘def’,’m’,3,4,5,6) với chuỗi thứ 2 từ information_schema.schemata. Và với chỉ 1 kí tự nó sẽ so sánh kí tự đó với kí tự đầu của chuỗi, ở đây là l và mysql sẽ tương đương với so sánh l với m. Và vì l&lt;&#x3D;m nên trả về true, m&lt;&#x3D;m nên cũng trả về true, và với n&gt;m nên trả về false. Vậy với việc select với boolean mà ra giá trị có nghĩa là kí tự đó vẫn đang &lt;&#x3D; kí tự cần tìm. Rồi đến khi clause là false tương đương với kí tự đó lớn hơn kí tự cần tìm, thì ta sẽ xác định kí tự trước đó là kí tự chúng ta cần tìm. Tương tự như thế và ta sẽ có được tên database đầu tiên. Tiếp tục chúng ta sẽ thay đổi limit clause để lấy từng database ra. Test trực tiếp bằng sql-labsXây dựng môi trường:Đầu tiên các bạn cần cài đặt docker, khá là dễ thôi nên các bạn tự mình cài lấy nhé. Cài đặt sqli-labs: Tiếp theo cài đặt Mysql 8: Trong terminal gõ docker ps để lấy id của container.Tiếp theo thay đổi cấu hình của sqli-labs: Tiếp theo sử dụng vim để thay đổi nội dung của file db-creds.inc. Hơi khó sử dụng, các bạn tự đọc nhé ^^. Cấu hình mysql: Thế là đã xong. Bây giờ gõ localhost trên trình duyệt là sẽ thấy trang web. Dump database: Vế phía sau and trả về true thì trên màn hình sẽ có Your Login name và Your Password, còn trả về false thì sẽ không xuất hiện gì cả. Từ đây chúng ta có thể sử dụng boolean sqli kết hợp câu lệnh table để dump ra database. Chúng ta cần lưu ý về kí tự cuối cùng, (&#39;def&#39;,&#39;mysql&#39;,3,4,5,6) sẽ không bằng với (table information_schema.schemata limit 0,1) nên kí tự cuối sẽ dừng ở chữ k, chuổi bây giờ sẽ là mysqk và với các kí tự nhiễu sau nó sẽ là không bằng và sẽ tiếp tục chạy. Ví dụ ở script dưới sẽ dừng khi i chạy hết 1 đến 20. Khi đó chúng ta có thể cho chạy vậy hoặc lọc cái đó ra vì nó không ảnh hưởng đến kết quả(các bạn test thì sẽ thấy ^^). Ví dụ: Script dump database: Dump table:Tìm số cột của bảng information_schema.tables: Vậy bảng này có 21 cột. Payload tiếp theo sẽ có dạng: Ở đây, ô đầu tiên là def, ô thứ 2 là database cần tìm table, ô thứ 3 là table. Các ô sau là không quan trọng. Tuy nhiên chúng ta cần phải limit table đúng với từng database. Không có một cách tìm cụ thể, nên việc test khoảng tìm là cần thiết. Đây là source cho việc dump table_name của mysql Hmm, ở trên k hay cho lắm cái này thuận lợi cho việc dò tìm hơn: Với payload của mình nếu không đúng index so với database thì nó sẽ có table_name là “__________________&#96;” hoặc là string trống. Để tìm đúng thì chúng ta sẽ dò đến khi có tên hợp lý. Script dump table_name: Dump column_name:Bảng này có 22 cột. Tương tự như information_schema.tables bảng này cần thêm 2 giá trị xác định là database và table, và dò khoảng đúng với database và table của column. Việc dò này các bạn lưu ý tự dò nhé, bởi vì với mỗi phiên bản sẽ có thêm những table và column nên nó chỉ gần sát với khoảng của mình thôi. Script dump column_name: Dump bảng đã được xác định:Mình không hiểu tại sao bây giờ giả sử giá trị cần tìm là dump, thì mình xét với dump thì nó vẫn trả về true. Nhưng mà cũng không quan trọng lắm, làm theo cái mình test thôi à ^^. huhu kĩ năng lập trình kém nên không biết viết như nào cho chuẩn nhất (lười quá), script của mình ở dưới bị dính thằng ‘0’ cách mình bypass chưa tối ưu, nếu giá trị có số 0 thì mình sai nhưng mà lười viết quá.Dump id: Dump username Dump password: HANDLER StatementSystax: Alias tên bảng: "},{"title":"Phân tích chuỗi Commons Collections 1 với TransformedMap","date":"2022-11-04T11:00:38.000Z","url":"/2022/11/04/Commons-Collections1-TransformedMap/","tags":[["Java","/tags/Java/"],["Deserialization","/tags/Deserialization/"],["Commons Collections","/tags/Commons-Collections/"]],"categories":[["Java","/categories/Java/"],["Deserialization","/categories/Java/Deserialization/"]],"content":"Một vài khái niệm cần nắmTrước tiên chúng ta cần hình dung lớp Runtime sẽ exec câu lệnh như nào, ở đây mình có sử dụng kiến thức reflection mà mình đã có bài viết về nó, các bạn có thể tham khảo thêm. Lớp java.lang.reflect.Method có phương thức invoke, nó dùng để invoke method của object được truyền vào ở tham số đầu tiên, và với các tham số của method này là Object args (tham số lưu dưới dạng object). Trong lớp Runtime có phương thức exec dùng để exec câu lệnh trên system. Bây giờ mình sẽ thực hiện invoke method exec của lớp runtime, vì nó là method private nên để sử dụng chúng ta cần setAccessible(“true”). Phân tíchSơ đồ tóm tắt chuỗi. InvokerTransformer.transformChain này bắt đầu từ lớp InvokerTransformer. Lớp này implements interface Transformer. Hàm tạo của lớp InvokerTransformer: Object[] args ở đây nhận một Object với kiểu String. Class[] paramTypes nhận một Object của lớp Class Trong trường structure tìm đến method transform trong class InvokerTransformer ta thấy: Đầu tiên, nó thực hiện lấy class của object input là tham số của phương thức transform. Tiếp theo nó thực hiện lấy phương thức với tên phương thức là tham số iMethodName của object của lớp InvokerTransformer, và iParamTypes là lớp đại diện cho kiểu tham số của phương thức này rồi gán vào object method có kiểu là Method.Sau đó nó thực hiện invoke method là iMethodName của của object input với tham số là iArgs. Có nghĩa khi chúng ta thực hiện invoker.transform(object) nó sẽ tương đương với việc chúng ta thực hiện invoke() method chứa trong biến invoker của object. Vậy nên ở đây chúng ta có thể sử dụng lớp InvokerTransformer để thực hiện lệnh exec của lớp Runtime. Tiếp theo chúng ta cần tìm lớp nào gọi đến phương thức transform của lớp InvokerTransformer. Ctrl + Chuột trái click vào phương thức transform: Phương thức này có nhiều lớp gọi đến, nhưng để có ảnh hưởng lead to CC1 chỉ có 2 lớp là TranformedMap và LazyMap. Bài viết này mình sẽ phân tích theo hướng TranformedMap. LazyMap mình sẽ phân tích sau. Cùng phân tích thôi nào~ TransformedMap.checkSetValueHàm này có 3 phương thức gọi đến method transform là checkSetValue, transformValue và transformKey. Tuy nhiên phương thức chúng ta cần đi vào là checkSetValue bởi vì nó được sử dụng ở những lớp khác và kéo theo một chuỗi gadget. Phương thức checkSetValue: Nhìn vào phương thức này chúng ta thấy khá tương đồng với đoạn code ngắn để exec calc với lớp InvokerTranformer rồi phải không. Bây giờ chúng ta sẽ xem valueTransformer là gì: valueTransformer là một object của lớp Transformer. Hàm tạo này khai báo protected nên không thể tạo trực tiếp, chúng ta cần tìm phương thức trả về object của lớp này. Trong lớp này có phương thức decorate return một object của TransformedMap, các tham số đầu vào tương ứng với các tham số của hàm tạo TransformedMap. Chúng ta sẽ dùng phương thức này để tạo gián tiếp một object của lớp TransformedMap. valueTransformer là một object kiểu Transformer nên chúng ta có thể truyền vào một object kiểu InvokerTransformer vì thằng này implements Transformer. Phương thức checkSetValue là phương thức protected nên chúng ta cần dùng reflection để gọi đến phương thức này. Chuỗi poc ngắn từ TranformedMap: Đây chỉ là một POC nhỏ, chỉ để chỉ ra rằng lớp TransformedMap có thể kích hoạt được phương thức của lớp Runtime. Vấn đề của chúng ta bây giờ là cần tìm ai gọi đến method checkSetValue này. AbstractMapEntryDecorator.MapEntryTiếp tục Ctrl + chuột trái click vào checkSetValue, ta thấy phương thức AbstractMapEntryDecorator.MapEntry.setValue() gọi đến checkSetValue. Lớp AbstractMapEntryDecorator là abstract cha của lớp TransformedMap. setValue là phương thức của lớp Map.Entry. Trước tiên chúng ta cần hiểu entry là gì à cách nó được sử dụng trong Map. Các bạn có thể tham khảo ở đây. Hàm setValue() sẽ thực hiện gán giá trị vào key. Với thư viện map, khi truy cập từng cặp khóa-giá trị (entry) này chúng ta sẽ dùng cách duyệt qua từng entry rồi thao tác với từng entry đó. Theo dõi hàm setValue: Phương thức setValue của interface java.util.Map được implements bởi lớp AbstractMapEntryDecorator, tiếp đến phương thức setValue của lớp này được Override bởi phương thức setValue của lớp AbstractInputCheckedMapDecorator.MapEntry. Khi duyệt map của lớp bằng AbstractInputCheckedMapDecorator.EntrySetIterator, phương thức next() return ra một AbstractInputCheckedMapDecorator.MapEntry.Do đó chúng ta có thể gọi đến hàm setValue() của AbstractInputCheckedMapDecorator.MapEntry. Lớp transformedMap implements lớp AbstractInputCheckedMapDecorator, do đó khi chúng ta decorate một map thành transformedMap và duyệt map bằng entrySet() kết hợp với iterator rồi thực hiện hàm setValue() của transformedMap, nó sẽ thực hiện hàm setValue của lớp AbstractInputCheckedMapDecorator.MapEntry, phương thức này sẽ gọi đến hàm checkSetValue(). Bạn nào mới học mà không hiểu thì đoạn Map.Entry entry : map.entrySet() là làm tắt bỏ bước define Iterator tuy nhiên nó cũng iterator bên trong đó nhé. Tiếp tục viết poc từ phương thức này: Nó đã kích hoạt được lệnh exec của lớp Runtime. Bây giờ chúng ta sẽ tìm xem có phương thức readObject nào gọi phương thức setValue này không. Click chuột phải vào hàm setValue và chọn Find Usage. Ở đây mình không thể tìm được lớp nào bởi vì mình chưa decompile trực tiếp các file trong jdk8u65, khá nhiều thứ để làm nên thôi mình sẽ tiếp tục làm theo sơ đồ của người ta. AnnotationInvocationHandlerCtrl + N để tìm lớp AnnotationInvocationHandler, trong phương thức readObject của lớp này, chúng ta thấy có phương thức setValue được gọi.Hàm tạo của lớp AnnotationInvocationHandler: Hàm readObject của lớp AnnotationInvocationHandler: Lớp AnnotationInvocationHandler có phạm vi default, nên chúng ta cần lấy lớp này và hàm tạo của nó thông qua reflection, sau đó khởi tạo nó. (stuck cũng lâu phết hic) Constructor của lớp Non-public phải lấy bằng phương thức getDeclaredConstructor(). Tham số thứ nhất của hàm tạo là một lớp, tham số thứ hai là một map. Một đoạn code nhỏ để test thử việc khởi tạo lớp AnnotationInvocationHandler: Đến đây vẫn chưa có gì xảy ra bởi vì: Đối tượng Runtime chưa được đặt vào hàm setValue. Và ở đây nó được set là object kiểu AnnotationTypeMismatchExceptionProxy, chúng ta không thể kiểm soát được. Chúng ta chưa làm thõa mãn hai điều kiện dẫn đến hàm setValue trong AnnotationInvocationHandler.readObject. Đối tượng Runtime không thể serialize và cần được chuyển đổi thành dạng có thể serialize thông qua reflection. Giải quyết vấn đề Runtime không thể serializeĐể thõa mãn được điều kiện serialize, mọi thứ trong nó đều phải serialize được. Tuy nhiên Runtime không thể serialize được, vậy nên chúng ta cần dùng Runtime.class để lúc deser, nó sẽ tạo một đối tượng Runtime cho chúng ta. Thay vì invoke trực tiếp, chúng ta có thể lợi dụng lớp InvokerTransformer để invoke hàm getRuntime hay invoke method và invoke exec của lớp runtime. Mình sẽ đi từng bước cho các bạn dễ hiểu.Đầu tiên là invoke method getDeclaredMethod để lấy ra method getRuntime. Tiếp theo là invoke biến getRuntimeMethod để tạo Runtime object. Rồi thực hiện invoke method exec của object runtime mới tạo ra. Để ý ở phần trên chúng ta có các InvokerTransformer nối tiếp nhau, để thuận tiện hơn người ta đã có tạo ra một lớp là ChainedTransformer, nó cũng thực hiện như InvokerTransformer tuy nhiên điểm khác là nó sẽ thực thi theo một chuỗi gắn kết với nhau. Chúng ta sẽ lợi dụng hàm này để thực thi tương tự như trên. ChainedTransformer Viết tiếp chain theo ChainedTranformer: Kết hợp với TransformedMap chúng ta có chuỗi hoàn chỉnh sau: Giải quyết vấn đề câu lệnh ifĐến đây chúng ta vẫn chưa giải quyết vấn đề AnnotationInvocationHandler.readObject sử dụng hàm setValue. Đến đây các bạn nên debug để xử lý dễ dàng hơn nhé. Đặt breakpoint ở dòng 339 và 341. Chúng ta cần var7 là một giá trị không null. Map var3 = var2.memberTypes(), var2 là một Object kiểu AnnotationType của lớp kế thừa Annotation mà ta truyền vào ở đoạn Object aihObject = aihClassConstructor.newInstance(Override.class, map);. var2 = AnnotationType.getInstance(this.type): var2 là một Object kiểu AnnotationType của lớp kế thừa Annotation mà ta truyền vào ở đoạn Object aihObject = aihClassConstructor.newInstance(Override.class, map); Code gốc khá là khó hiểu nên các bạn cứ hiểu đơn giản là trong AnnotationType có biến là memberTypes là một map với key là tên của biến trong Override.class mình cho vào, và value là kiểu của biến này. Ta gọi var2.memberTypes() sẽ trả về map này.Vậy là lỗi ở đây xảy ra do interface Override không có biến nào cả. Chúng ta cần tìm Annotation khác có biến, ở đây chúng ta có annotation Target có một biến. Và đặt lại giá trị trong map là key=value và value=bất kỳ: Chúng ta đã vượt qua được if đầu tiên, và đồng thời if thứ 2 cũng đã vượt qua (không cần để ý đến vì toàn code gốc, đọc vào sẽ tốn thời gian của chúng ta thui à). Tuy nhiên vẫn chưa đủ để exec calc bởi vì chúng ta chưa xử lý vấn đề không điều khiển được AnnotationTypeMismatchExceptionProxy. Giải quyết vấn đề không điều khiển được AnnotationTypeMismatchExceptionProxy Đến đây mọi thứ được lập trình ra vẫn hỗ trợ cho chain của chúng ta :), lớp ConstantTransformer tương tự như InvokerTransformer tuy nhiên khi thực hiện transform, thằng ConstantTransformer sẽ trực tiếp return ra Object mình truyền vào ở hàm tạo chứ không phải Object truyền vào ở hàm Transform, Object này sẽ nối tiếp cho chuỗi sau.Vậy là chúng ta có thể thực hiện x.Transform(new AnnotationTypeMismatchExceptionProxy....) Từ đây chúng ta có chuỗi hoàn chỉnh sau: Chạy file và máy tính đã bật lên… Lời kếtVà đến đây là mình đã hoàn thành chain Commons Collections 1 theo hướng TransformedMap, là chain đầu tiên mình làm và bước chân vào con đường Java Security.Thật sự, khi đọc mã nguồn từ nhà phát hành và tìm hiểu cách các master OOP sử dụng các thư viện, mình nhận thấy rất nhiều kiến thức mình chưa có. Tuy nhiên, nhờ đó, mình đã học được nhiều kiến thức mới về Java OOP.Hy vọng các bạn nào mới bước chân vào Java Security như mình hãy cố gắng nghiên cứu, đọc hiểu từ từ để có thể hiểu một cách rõ nhất về cái đẹp của Java OOP. Thực sự rất khó cho người mới học nên hy vọng các bạn có thể vượt qua ^^. Chúc các bạn học tốt~ "},{"title":"Introduction to Java Deserialization","date":"2022-11-02T19:50:28.000Z","url":"/2022/11/03/JavaDeserializationBasic/","tags":[["Java","/tags/Java/"],["Deserialization","/tags/Deserialization/"]],"categories":[["Java","/categories/Java/"],["Deserialization","/categories/Java/Deserialization/"]],"content":"Bài viết này là về những concept cơ bản của quá trình Serialization và Deserialization và cách mà lỗ hổng Java Deserialization được thực thi. Serialization và Deserialization1. Serialization và deserialization là gì?Hiểu một cách đơn giản hai quá trình này là: Serialization: Object –&gt; string hay bytecode(với Java) Deserialization: string hoặc bytecode –&gt; Object 2. Những quá trình cần sử dụng đến Serialization:Lưu các đối tượng (ở đây xem như dữ liệu) vào bộ nhớ, tệp, cơ sở dữ liệu,…Truyền các đối tượng qua mạng.Chuyển đối tượng qua RMI. 3. Triển khai quá trình Ser và Deser cơ bản:Ở đây mình tạo một package SerialBasic rồi cho các lớp vào trong package đó. File Person.java File SerializationTest.java File DeserializationTest.java Đầu tiên ta chạy file SerializationTest.java, sau khi chạy xong ta thấy ở trong thư mục cha của src có một file ser.txt mới được tạo.Tiếp đến chạy file DeserializationTest.java: Giải thích: SerializationTest.javaBan đầu chúng ta khởi tạo một object new FileOutputStream(“ser.txt”), tiếp đến chúng ta khởi tạo một ObjectOutputStream. Rồi thực hiện oos.writeObject(obj) để viết đối tượng vào file ser.txt DeserializationTest.java Cách mà lỗ hổng Deserialization xảy ra:Ở đây mình dùng Intellij để thực hiện, một IDEA rất tiện lợi mà ai làm việc với Java đều sử dụng.Mình chỉ nói đến một chuỗi cơ bản để các bạn có thể hình dung cách thực hiện và bắt đầu với Deserialization trong Java nhé ^^. 1. HashMap và cách nó gây ra lỗ hổng Deserialization:Gõ Ctrl + N và tìm kiếm lớp HashMap: Lớp HashMap này có implements lớp Serializable vậy nên chúng ta có thể dùng nó để lợi dụng quá trình Ser và Deser. Tiếp theo mở phần Structure và tìm kiến method readObject của lớp HashMap: Trong method readObject ta thấy có phần quan trọng ở đây: Đầu tiên thực hiện gán key và value &#x3D; s.readObject() Sau đó thực hiện hàm putVal(), điểm cần chú ý ở đây là nó đưa key vào method hash(). Ctrl + Chuột trái để đi vào phương thức hash():Trong phương thức hash này, nếu key &#x3D;&#x3D; null sẽ return 0, còn không thì sẽ thực hiện h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) rồi return h.Điểm mà chúng ta cần chú ý ở đây là nó thực hiện key.hashCode() mình sẽ đi sâu một chút cho các bạn dễ hiểu: Trong Java có một lớp là cha của mọi lớp đó là lớp Object, nó có các phương thức như toString(), hashCode(),… key là một object của lớp hashMap mà implements ngầm lớp Object (vì nó cha của mọi lớp mà) vậy nên nó thừa hưởng các phương thức của lớp Object. Nên ở đây chúng ta có thể gọi key.hashCode() Việc gọi hashCode() ở đây có ý nghĩa gì thì chúng ta cùng đi sâu vào chuổi URLDNS nhé! 2. Phân tích chuỗi URLDNS:Chuỗi URLDNS là một chuỗi đơn giản nhất trong các gadget chain (đương nhiên sẽ hơi khó hiểu với người bắt đầu, keep going ^^). Chuỗi này không thực sự gây ra một vấn đề gì nghiêm trọng như là RCE hay là SSRF…, kết quả của chuỗi này là thực hiện một yêu cầu DNS đến địa chỉ mà chúng ta đưa vào. Nó có kết quả phải không nào ^^, vậy nên chuỗi này sẽ giúp các bạn biết được một gadget chain sẽ xảy ra như thế nào. Cố gắng viết code, đọc hiểu để nhanh tiến bộ nhé ٩(^‿^)۶… Chuỗi thực thi của URLDNS như sau: Để tạo một HashMap, đầu tiên chúng ta thực hiện tạo một object hashmap, sau đó chúng ta sẽ thực hiện hàm put() để đưa dữ liệu vào trong object HashMap đó. Ở đây tham số đầu tiên của hàm put() là một object key, và tham số thứ hai là value. Hai biến này tương ứng với key và value mình đã phân tích ở trên phần phân tích về HashMap. Ở đây vì key nhận vào là một object nên ở đây chúng ta sẽ tạo một object URL để thực hiện chain này.Bây giờ, giả sử như chúng ta thực hiện readObject hashmap, nó sẽ đi theo sơ đồ: Và đến đây, phương thức hashCode() được gọi sau khi readObject() sẽ phát huy tác dụng. Chúng ta sẽ đi sâu vào phần này:Tiếp tục chúng ta tìm class URL rồi tìm đến method hashCode(). Ở đây, phương thức hashCode() của lớp Object đã được định nghĩa lại trong lớp URL: Nếu hashCode không bằng -1 thì sẽ thực hiện return hashCode bởi vì nó đã được set rồi. Nếu không thì hashCode sẽ được gán bằng handler.hashCode(this), this ở đây có nghĩa là nó sẽ lấy object của lớp hiện tại đưa vào handler.hashCode rồi thực hiện tiếp.Tiến hành Ctrl+Chuột trái rồi nhấn vào handler để đi đến nơi mà biến hanler được tạo.Ảnh biến handler Biến handler ở đây là một object của lớp URLStreamHandler, object này sẽ gọi đến phương thức hashCode() được định nghĩa trong lớp này. Tiến hành Ctrl+Chuột trái rồi click vào URLStreamHandler, rồi tìm đến phương thức hashCode(). Trong phương thức này chúng ta thấy dòng InetAddress addr = getHostAddress(u); có nghĩa là nó sẽ thực hiện một yêu cầu DNS đến địa chỉ URL để thực hiện getHostAddress. Đến đây ta đạt được mục đích của Chain này đó là request đến địa chỉ URL mà ta cung cấp. Còn lại phần sau và việc nó thực hiện request thế nào thì chúng ta không cần quan tâm, chỉ vậy là đã đủ (Đương nhiên bạn nào thích thì cứ tìm hiểu nhé ^^). 3. POC cho chuỗi URLDNS:Link nhận DNS request:  Chú ý khi thực hiện serialize object của lớp HashMap:Filename: SerializeTest.java Sau khi chạy file này, dù chưa thực hiện deserialize file Ser2.txt mà chúng ta đã nhận được request đến. Nguyên nhân là do khi thực hiện gán giá trị vào object hashmap bằng hashmap.put(), hàm hash trong phương thức này đã được thực hiện và sẽ request đến địa chỉ URL mà ta cung cấp.Sau khi request đến URL, biến hashcode bây giờ đã không còn là -1 nữa, khi đó trong quá trình deserialize request sẽ không được gửi đến. Vậy nên sau khi thực hiện deserialize, chúng ta cần thực hiện set lại giá trị cho hashcode là -1. Tuy nhiên vấn đề ở đây là biến hashcode là private, để gán lại giá trị cho biến private chúng ta cần sử dụng đến Reflection mà mình đã có bài viết về nó. POC hoàn thiện của chuỗi URLDNS:file: SerializeTest.java file: Deser.java Kết quả: Vậy là mình đã giới thiệu xong về cơ bản của quá trình Deserialization và đi qua hết chuỗi URLDNS. Đây chỉ là những kiến thức cơ bản của lỗ hổng Java Deserialization. Để hiểu sâu hơn về lỗ hổng này, mình thực sự khuyên các bạn hãy hiểu tường tận về những keyword sau: “Class Class”, “Class Object”, “Class Runtime”, “Reflection”, các khái niệm về OOP, và còn nhiều thứ khác nữa. Và hãy cố gắng đọc hiểu và tự mình viết POC cho lỗ hổng này, khá khó để bắt đầu nhưng hi vọng các bạn có thể vượt qua. Hành trình nào mà không có gian nan, đau khổ ^^… Chúc các bạn học tốt~ "},{"title":"Java Reflection","date":"2022-11-02T16:23:23.000Z","url":"/2022/11/02/Java-reflection/","tags":[["Java","/tags/Java/"],["Reflection","/tags/Reflection/"],["Programming","/tags/Programming/"]],"categories":[["Java","/categories/Java/"],["Programming","/categories/Java/Programming/"]],"content":"Lớp Java Reflection là một lớp thường xuyên được sử dụng vì sự tiện nghi của nó, nên chúng ta cũng có thể thường xuyên thấy những lớp này khi đi sâu vào những lỗ hổng của Java. Ngoài ra, trong Java Deserialization ta thường dùng lớp này để có thể truy cập vào các thuộc tính Private. Trước khi đọc bài viết này, các bạn nên tìm hiểu lớp Class, Object. Tản mạn thế là đủ rồi, ta cùng đi vào bài viết nào o(￣▽￣)ブ Java Reflection1. Khái niệm:Reflection là một tính năng của java, nó cho phép một chương trình đang chạy trực tiếp lấy ra các thuộc tính, phương thức,… và thao tác với nó. Một điểm đặc biệt của Java reflection là nó cho phép thay đổi các thuộc tính Private của một Object. 2. Các hàm của Java reflection:Ở đây mình chỉ liệt kê ra những hàm thường dùng của Reflection. Lấy ra thuộc tính của một lớp (Field):Trong lớp Class có hai phương thức để lấy ra trường ở trong một lớp là getDeclaredFields() và getDeclaredField(String name). Phương thức getDeclaredFields() sẽ lấy ra tất cả những trường có ở trong class của object đó. Phương thức getDeclaredField(String name) sẽ lấy ra một trường có tên là String mà chúng ta truyền vào. Hai phương thức này tương tự nhau chỉ là phương thức getDeclaredFields() sẽ lấy ra tất cả các field của Class đó rồi cho vào một mảng nên các bạn tự tìm hiểu nhé.. Lấy ra phương thức của một lớp: Method Public Non-public Inherited getMethod &amp; getMethods ✔️ ❌ ✔️ getDeclaredMethod &amp; getDeclaredMethods ✔️ ✔️ ❌ Phương thức getMethod() và getMethods():Hàm getMethod() và getMethods() sẽ có thể lấy những method public và những method được kế thừa từ lớp cha của nó. Lớp getMethod() sẽ trả về một phương thức xác định, còn lớp getMethods() sẽ trả về một mảng các phương thức. Phương thức getDeclaredMethod() và getDeclaredMethods():Hàm getDeclaredMethod() và getDeclaredMethods() sẽ lấy ra những phương thức được định nghĩa ở trong class hiện tại, bao gồm cả Public và Non-public nhưng không thể lấy những class kế thừa như của getMethod(). Tương tự như vậy, lớp getDeclaredMethod() sẽ trả về một phương thức xác định, còn lớp getDeclaredMethods() sẽ trả về một mảng các phương thức. Các phương thức đều tương tự nhau nên mình sẽ chỉ đưa ra một ví dụ: Class.getMethod() nhận tham số đầu là string với tên của method, các tham số sau là lớp của đối số mà method cần lấy ra nhận vào. Như ví dụ trên, lớp work nhận vào 2 tham số là String nên chúng ta sẽ truyền vào String.class,… method lấy ra bây giờ là một object của lớp Method bây giờ nó đại diện cho các method của những object thuộc chung một class có method được lấy ra. Trong lớp Method có một hàm invoke() dùng để gọi cái method đó. Và đương nhiên method bây giờ chưa phải là của object nào mà nó chỉ chung chung, bây giờ hàm invoke() sẽ nhận đối số đầu tiên là object chứa method đó, các giá trị sau là các tham số của method. Lưu ý method chỉ sử dụng nếu các object là chung một class. Phương thức getConstructor() và getConstructors():Phương thức này giúp chúng ta lấy ra một Constructor của một lớp và đưa vào lớp Constructor, từ Constructor được lấy ra, chúng ta có thể tạo một Object bằng hàm newInstance() ở trong lớp Constructor.Phương thức getConstructors() tương tự, chỉ khác là nó sẽ đưa vào mảng. Lấy ra một lớp mà không thể thao tác trực tiếp:Phương thức forNameĐể lấy ra một class chúng ta dùng phương thức forName. "},{"title":"HTTP request smuggling với HTTP/2.0","date":"2022-11-02T16:23:23.000Z","url":"/2022/11/02/http-request-smuggling-HTTP-2.0/","tags":[["HRS","/tags/HRS/"]],"categories":[["HTTP Request Smuggling","/categories/HTTP-Request-Smuggling/"]],"content":"Lời nói đầu:Bài viết trước mình đã nói về khái niệm cơ bản của HRS và một số dạng cơ bản với HTTP&#x2F;1.1. Bài viết này mình sẽ đi vào HRS với HTTP&#x2F;2.0, nó khá phức tạp hơn so với HTTP&#x2F;1.1 tuy nhiên cũng không khó lắm đâu ^^. Cùng đi vào bài nhé~ HTTP request smuggling với HTTP&#x2F;2.0Tham khảo:  HTTP&#x2F;2 downgradingNguồn gốc chính của lỗ hỏng này là front-end server sử dụng giao thức HTTP&#x2F;2 để giao tiếp với máy khách trong khi đó nó lại dùng HTTP&#x2F;1.1 để giao tiếp với back-end server. Khi đó user có thể chèn thêm các phần độc hại vào header mà hợp lệ với HTTP&#x2F;2, tuy nhiên nó lại được phân tích ở máy chủ back-end với giao thức HTTP&#x2F;1.1, khi đó lỗi HRS sẽ xảy ra. Front-end HTTP&#x2F;2 server thường sử dụng message length có sẵn trong các data frames gửi đi theo giao thức này. Trong khi để Backend hiểu được thì cần downgrade xuống HTTP&#x2F;1 bao gồm 2 loại là TE và CL dẫn đến lỗi H2-TE và H2-CL. H2.CL Desync:Theo HTTP&#x2F;2 RFC, ta có độ dài ở trong mỗi frame do đó tiêu đề Content-length là không cần thiết, tuy nhiên vẫn có thể đặt Content-length trong header. Khi user gửi request đến front-end server có chứa trường Content-Length, front-end server có thể sẽ chấp nhận trường này dù độ dài không đúng. Sau đó nó sẽ hạ cấp request từ HTTP&#x2F;2.0 xuống HTTP&#x2F;1.1 và giữ nguyên trường Content-Length, tại back-end server nó có phân tích trường Content-Length với giá trị mà user cho vào, bây giờ user có thể chèn thêm các phần độc hại và một giá trị Content-Length không phù hợp với server để trigger HRS. Ví dụ: Sau khi hạ cấp nó sẽ tạo thành yêu cầu như sau: Sau khi front-end server gửi yêu cầu đến back-end server phần còn lại sẽ được xem như là của yêu cầu mới, khi một người dùng khác gửi yêu cầu đến cùng thời điểm, phần còn lại sẽ được gắn vào đầu của yêu cầu mới và lỗi HRS được kích hoạt. Trả về 200 OKYêu cầu của nạn nhân sẽ trở thành yêu cầu sau: Trả về 404 Not Found H2.TEH2.TE Desync - Máy chủ Front-end downgrade H2 thành H1 và không xem xét loại bỏ các trường liên quan đến connection-specific header fieldsRequest gửi đến FE server: :method POST :path &#x2F;identitfy&#x2F;XUI :authority id.b2b.oath.com transfer-encoding chunked FE downgrade mà không tuân thủ việc loại bỏ transfer-encoding: Phía server chọn transfer encoding và H2.TE xảy ra, tương tự như CL.TE. Bây giờ request sẽ trở thành: Request 1 Request 2 H2.TE via Request Header InjectionRequest gửi đến FE server: :method POST :path &#x2F; :authority start.mozilla.org foo b\\r\\n transfer-encoding: chunked Sau khi FE downgrade, \\r\\n trigger header injection: Bây giờ bài toán lại trở về H2.TE HTTP request tunnellingClient-side DesyncTham khảo:  Đôi khi server sẽ trả về 2 response với cùng một request nếu Connection là keep-alive và gửi chung 2 request trong 1 request. Để server phân biệt được khi nào 2 request, khi nào thì chỉ là 1 request và phần sau là phần body thì ta cần thêm giá trị content-length. Tuy nhiên một vài server sẽ không mong đợi Content-Length và sẽ mặc định là 0. Khi này server sẽ nghĩ đó là 2 request dù đó là POST request như sau: Và 2 response sẽ được trả về. Pause-based desync "}]